{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:40.483313Z",
     "start_time": "2024-06-02T11:25:40.468365Z"
    }
   },
   "source": [
    "# A notebook to evaluate GNN explainer performance by calculating Comprehensiveness and Sufficiency \n",
    "#     as defined in \"BAGEL: A Benchmark for Assessing Graph Neural Network Explanations\", by Rathee et al. (2022). \n",
    "# \n",
    "#     Model training and explanation generation adapted from the original MolRep code by Tim Stols.\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "d717205e-5947-4c39-b14b-320ceebf664b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:40.499285Z",
     "start_time": "2024-06-02T11:25:40.486307Z"
    }
   },
   "source": [
    "# Converted by Tim Stols\n",
    "# python Explainer_Experiments.py --model_name CMPNN \\\n",
    "#                                                        --attribution_name GradInput \\\n",
    "#                                                        --data_path ../MolRep/Datasets/Metabolism/admet2.1_rlm_merge.csv \\\n",
    "#                                                        --dataset_name RLM \\\n",
    "#                                                        --smiles_col COMPOUND_SMILES \\\n",
    "#                                                        --target_col CLF_LABEL \\\n",
    "#                                                        --task_type Multi-Classification \\\n",
    "#                                                        --multiclass_num_classes 3 \\\n",
    "#                                                        --output_dir ../Outputs"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "97e7da87e9d3f7b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:40.530220Z",
     "start_time": "2024-06-02T11:25:40.503261Z"
    }
   },
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "LOADING_FROM_FILES = True # True if loading in data from pre-existing files\n",
    "\n",
    "# output directory for trained model and explanations\n",
    "OUTPUT_DIR = f'../Outputs/Experiment'\n",
    "# OUTPUT_DIR = '../Outputs' # original output path, overwrites results\n",
    "\n",
    "# output the explanations (optionally model) here\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "DATASET = 'Benzene'\n",
    "# DATASET = '3MR'\n",
    "\n",
    "# GNN\n",
    "MODEL = 'CMPNN' # Options:  ['MPNN', 'DMPNN', 'CMPNN', 'GIN', 'ECC', 'GAT', 'DGCNN', 'DiffPool', 'GraphSAGE', 'GraphNet']\n",
    "\n",
    "# use specified model, else train a new one\n",
    "# MODELPATH = None\n",
    "MODELPATH = '../Outputs/Experiment/CMPNN_Benzene_explainer/CMPNN_1_epoch.pt' # using this model because it has non-zero F1 score\n",
    "# MODELPATH = '../Models/CMPNN_3MR_explainer_20240519_143138.pt'\n",
    "\n",
    "if MODELPATH is None:\n",
    "    MODELPATH = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", f\"{MODEL}.pt\")\n",
    "\n",
    "# explainers used on the trained model, overwritten down below for testing purposes\n",
    "ATTRIBUTIONS = ['IG', 'Random'] # Options: IG CAM MCTS GradInput GradCAM RandomBaseline # this says RandomBaseLine but code expects 'Random'\n",
    "\n",
    "DATAPATH = '../Datasets/XAI/Benzene/benzene_smiles.csv'\n",
    "# DATAPATH = '../DataSets/3MR/toy_label_mw350.csv'\n",
    "SMILESCOL = 'SMILES'\n",
    "TARGETCOL = 'label'\n",
    "# TARGETCOL = 'label_full' # for 3MR, on my machine the functions targets the wrong label, even if the offending column is deleted\n",
    "\n",
    "ATTRIBUTIONPATH = '../Datasets/XAI/Benzene/attributions.npz'\n",
    "# ATTRIBUTIONPATH = '../DataSets/3MR/attributions.npz'\n",
    "\n",
    "\n",
    "TASKTYPE = 'Classification' # Can be 'Multi-Classification', 'Classification', 'Regression'\n",
    "MULTICLASS_NUM_CLASSES = 2 # Can be 3\n",
    "TESTING = True\n",
    "SPLITTYPE = 'defined' # Can be 'random', 'scaffold', or other defined for dataset\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "dfacd7f1cf8943f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:55.321312Z",
     "start_time": "2024-06-02T11:25:40.565096Z"
    }
   },
   "source": [
    "import rdkit.Chem\n",
    "from MolRep.Utils.logger import Logger\n",
    "from MolRep.Explainer.explainerExperiments import ExplainerExperiments\n",
    "from MolRep.Explainer.explainerDataWrapper import ExplainerDatasetWrapper\n",
    "from MolRep.Utils.config_from_dict import Grid, Config, DatasetConfig\n",
    "from pathlib import Path\n",
    "import os\n",
    "# from numba.cuda import args\n",
    "\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "# set up the model\n",
    "data_stats = {\n",
    "            'name': DATASET,\n",
    "            'path': DATAPATH,\n",
    "            'smiles_column': SMILESCOL,\n",
    "            'target_columns': [TARGETCOL],\n",
    "            'attribution_path': ATTRIBUTIONPATH,\n",
    "            'task_type': TASKTYPE,\n",
    "            'multiclass_num_classes': MULTICLASS_NUM_CLASSES,\n",
    "            'metric_type': 'rmse' if TASKTYPE == 'Regression' else ['acc', 'auc', 'f1', 'precision', 'recall'],\n",
    "            'split_type': SPLITTYPE\n",
    "}\n",
    "\n",
    "if TESTING:\n",
    "    data_stats['additional_info'] = {\"splits\":'SPLIT'}\n",
    "    \n",
    "# output for vector groups\n",
    "data_dir = Path('../MolRep/Data')\n",
    "split_dir = Path('../MolRep/Splits')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(split_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b4e5f3f497340e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:55.399109Z",
     "start_time": "2024-06-02T11:25:55.324309Z"
    }
   },
   "source": [
    "config_file = '../MolRep/Configs/config_{}.yml'.format(MODEL)\n",
    "model_configurations = Grid(config_file)\n",
    "model_configuration = Config(**model_configurations[0])\n",
    "dataset_configuration = DatasetConfig(DATASET, data_dict=data_stats)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMPNN\n",
      "{'GIN': <class 'MolRep.Models.graph_based.GIN.GIN'>, 'ECC': <class 'MolRep.Models.graph_based.ECC.ECC'>, 'DGCNN': <class 'MolRep.Models.graph_based.DGCNN.DGCNN'>, 'DiffPool': <class 'MolRep.Models.graph_based.DiffPool.DiffPool'>, 'GraphSAGE': <class 'MolRep.Models.graph_based.GraphSAGE.GraphSAGE'>, 'GAT': <class 'MolRep.Models.graph_based.GAT.GAT'>, 'GraphNet': <class 'MolRep.Models.graph_based.GraphNet.GraphNet'>, 'MPNN': <class 'MolRep.Models.graph_based.MPNN.MPNN'>, 'CMPNN': <class 'MolRep.Models.graph_based.CMPNN.CMPNN'>, 'DMPNN': <class 'MolRep.Models.graph_based.DMPNN.DMPNN'>, 'MAT': <class 'MolRep.Models.sequence_based.MAT.MAT'>, 'CoMPT': <class 'MolRep.Models.sequence_based.CoMPT.CoMPT'>, 'BiLSTM': <class 'MolRep.Models.sequence_based.BiLSTM.BiLSTM'>, 'SALSTM': <class 'MolRep.Models.sequence_based.SALSTM.SALSTM'>, 'Transformer': <class 'MolRep.Models.sequence_based.Transformer.Transformer'>, 'VAE': <class 'MolRep.Models.unsupervised_based.VAE.VAE'>, 'RandomForest': <class 'MolRep.Models.unsupervised_based.RandomForest.RandomForest'>, 'XGboost': <class 'MolRep.Models.unsupervised_based.XGboost.XGboost'>, 'PLNLP': <class 'MolRep.Interactions.link_models.PLNLP.PLNLP.PLNLP'>, 'CFLP': <class 'MolRep.Interactions.link_models.CFLP.CFLP.CFLP'>}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "6f5aafb16b07d4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.493131Z",
     "start_time": "2024-06-02T11:25:55.401103Z"
    }
   },
   "source": [
    "# export path: model + dataset name\n",
    "exp_path = os.path.join(output_dir, f'{model_configuration.exp_name}_{dataset_configuration.exp_name}_explainer')\n",
    "\n",
    "# dataset_config: configuration of the model\n",
    "# model_name: name of the model\n",
    "# split_dir: path to defined splits of the dataset\n",
    "# features_dir: path to data directory\n",
    "dataset = ExplainerDatasetWrapper(dataset_config=dataset_configuration,\n",
    "                                  model_name=model_configuration.exp_name,\n",
    "                                  split_dir=split_dir, features_dir=data_dir)\n",
    "\n",
    "# set up the experiment\n",
    "explainer_experiment = ExplainerExperiments(model_configuration, dataset_configuration, exp_path)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "72368846a986d178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.664158Z",
     "start_time": "2024-06-02T11:25:58.496197Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# import torch\n",
    "\n",
    "# to load a model from a file without having used it, need to instantiate it first\n",
    "# model = CMPNN(model_configuration)\n",
    "# state_dict = torch.load(MODELPATH)\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "# Options: IG CAM MCTS GradInput GradCAM RandomBaseline # says RandomBaseLine but code expects 'Random'\n",
    "ATTRIBUTIONS = []\n",
    "\n",
    "atom_importances = []\n",
    "explainer_accuracies = []\n",
    "\n",
    "if LOADING_FROM_FILES :\n",
    "    LOGGER_BASE = os.path.join(OUTPUT_DIR, \"Logger\", f\"{DATASET}_explainer\")\n",
    "    logger = Logger(str(os.path.join(LOGGER_BASE, f\"{MODEL}_{DATASET}_explainer_by_experiment.log\")), mode='a')\n",
    "    \n",
    "    ### TODO on first run, uncomment, on subsequent runs can leave commented out ###\n",
    "    # _, _, _ = explainer_experiment.molecule_importance(dataset=dataset, attribution=ATTRIBUTIONS[0], logger=logger, other={'model_path':MODELPATH}, testing=TESTING)\n",
    "    \n",
    "    # read in used explainers\n",
    "    explainer_accs_path = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\" , f\"explainer_accuracies.csv\")\n",
    "    explainer_accuracies_df = pd.read_csv(explainer_accs_path) # used for looking at, nothing else\n",
    "    \n",
    "    for e in explainer_accuracies_df['explainer']:\n",
    "        ATTRIBUTIONS.append(e)\n",
    "    \n",
    "    # get atom importances per explainer\n",
    "    for ATTRIBUTION in ATTRIBUTIONS:\n",
    "        atom_imp_for_expl = []\n",
    "        \n",
    "        imp_path = os.path.join(output_dir, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}_{model_configuration['num_epochs']}_epochs\" , \"importances.csv\")\n",
    "\n",
    "        # atom importances are given as a string of an array of floats \n",
    "        importance = pd.read_csv(imp_path)['Atom_importance']\n",
    "        \n",
    "        for _, row in importance.items():\n",
    "            # remove brackets and newlines\n",
    "            clean_imp = re.sub(r'[\\[\\]\\n]', '', row).strip()\n",
    "            \n",
    "            # split by whitespace and convert to float\n",
    "            float_imps = [float(x) for x in clean_imp.split()]\n",
    "            atom_imp_for_expl.append(float_imps)\n",
    "\n",
    "        atom_importances.append(atom_imp_for_expl)    \n",
    "    \n",
    "else: \n",
    "    ATTRIBUTIONS = ['IG', 'GradCAM', 'Random']\n",
    "    # generate explanations for each explainer\n",
    "    for ATTRIBUTION in ATTRIBUTIONS:\n",
    "        LOGGER_BASE = os.path.join(OUTPUT_DIR, \"Logger\", f\"{DATASET}_explainer\")\n",
    "        logger = Logger(str(os.path.join(LOGGER_BASE, f\"{MODEL}_{DATASET}_explainer_by_{ATTRIBUTION}.log\")), mode='a')\n",
    "        \n",
    "        # define path for graphics\n",
    "        svg_dir = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}_{model_configuration['num_epochs']}_epochs\")\n",
    "        os.makedirs(svg_dir, exist_ok=True)\n",
    "    \n",
    "        ### comment out if a model exists and want to use it with all models, else trains a new one for each ###\n",
    "        # explainer_experiment.run_valid(dataset, ATTRIBUTION, logger=logger, other={'model_path':MODELPATH})\n",
    "    \n",
    "        ## if model doesn't exist, train a new one\n",
    "        # if not os.path.exists(MODELPATH):\n",
    "        #     explainer_experiment.run_valid(dataset, ATTRIBUTION, logger=logger, other={'model_path':MODELPATH})\n",
    "        \n",
    "        # generate attributions; bond_importance is None in all the tests I ran\n",
    "        results, atom_importance, bond_importance = explainer_experiment.molecule_importance(dataset=dataset, attribution=ATTRIBUTION, logger=logger, other={'model_path':MODELPATH}, testing=TESTING)\n",
    "        \n",
    "        if DATASET in ['hERG', 'CYP3A4']:\n",
    "            attribution_results, opt_threshold = explainer_experiment.evaluate_cliffs(dataset, atom_importance, bond_importance)\n",
    "        else:\n",
    "            binary = True if ATTRIBUTION == 'MCTS' else False\n",
    "            #TODO \"not working, because ATTRIBUTIONPATH is not set and attributions are not saved\"\n",
    "            attribution_results, opt_threshold = explainer_experiment.evaluate_attributions(dataset, atom_importance, bond_importance, binary=binary)\n",
    "         \n",
    "        # creates visualizations from the datasets and outputs them to svg_dir\n",
    "        explainer_experiment.visualization(dataset, atom_importance, bond_importance, svg_dir=svg_dir, testing=TESTING)\n",
    "    \n",
    "        # write the results, atom importances to a file\n",
    "        df = pd.DataFrame(\n",
    "            {'SMILES': dataset.get_smiles_list(), 'Atom_importance': atom_importance, 'Bond_importance':bond_importance}\n",
    "        )\n",
    "        df.to_csv(os.path.join(svg_dir, \"importances.csv\"), index=False)\n",
    "    \n",
    "        # create an object from the pre-established metrics, add to list (include model results to ensure they're all the same)\n",
    "        acc = {\"explainer\" : ATTRIBUTION,\n",
    "               \"model\" : MODEL,\n",
    "                \"epochs\" : model_configuration['num_epochs'],\n",
    "                \"acc\" : results['acc'],\n",
    "                \"auc\" : results['auc'], \n",
    "                \"f1\" : results['f1'], \n",
    "                \"precision\" : results['precision'], \n",
    "                \"recall\" : results['recall'], \n",
    "                \"Attribution AUROC\" : attribution_results['Attribution AUROC'], \n",
    "                \"Attribution F1\" : attribution_results['Attribution F1'], \n",
    "                \"Attribution ACC\" : attribution_results['Attribution ACC'], \n",
    "                \"Attribution Precision\" : attribution_results['Attribution Precision'], \n",
    "                \"Attribution AUROC Mean\" : attribution_results['Attribution AUROC Mean'], \n",
    "                \"Attribution ACC Mean\" : attribution_results['Attribution ACC Mean'] }\n",
    "        explainer_accuracies.append(acc)\n",
    "    \n",
    "        # add atom importances to a list, fetch them by index of attributions on the list used\n",
    "        # importance = {\"Atom_importance\" : atom_importance}\n",
    "        atom_importances.append(atom_importance)\n",
    "       \n",
    "    # TODO store these in a file\n",
    "    explainer_accuracies_df = pd.DataFrame(explainer_accuracies)\n",
    "    \n",
    "    # dataframe for storing atom importances per explainer in a file later\n",
    "    importances_df = pd.DataFrame(atom_importances)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "26dc4c46c4a7d504",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.696109Z",
     "start_time": "2024-06-02T11:25:58.668157Z"
    }
   },
   "source": [
    "import copy\n",
    "\n",
    "# path to model and explanations\n",
    "\n",
    "x = os.path.join(output_dir, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"IG_{model_configuration['num_epochs']}_epochs\" , \"importances.csv\")\n",
    "# IMPORTANCES_PATH = '../Outputs/20240524_164403/CMPNN_Benzene_explainer/SVG/IG_1_epochs/importances.csv' \n",
    "\n",
    "# os.path.join(output_dir, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}_{DATASET}_explainer\" , \"importances.csv\")\n",
    "IMPORTANCES_PATH = x\n",
    "\n",
    "\n",
    "# svg_dir = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}_{model_configuration['num_epochs']}_epochs\")\n",
    "# df.to_csv(os.path.join(svg_dir, ), index=False)\n",
    "\n",
    "# df = pd.read_csv(IMPORTANCES_PATH)\n",
    "# print(df['Atom_importance'].iat[3])\n",
    "\n",
    "# TODO if reading importances from a csv, must convert importances from a string of an array of floats to an actual array of floats\n",
    "# TODO write explainer_accuracies and atom importances to a file if they arent already\n",
    "# TODO write a method to import them back to notebook\n",
    "\n",
    "# y = os.path.join(output_dir, f\"{MODEL}_{DATASET}_explainer\", f\"{model_configuration['num_epochs']}_epochs\")\n",
    "# os.makedirs(y, exist_ok=True)\n",
    "\n",
    "# df.to_csv(os.path.join(svg_dir, \"importances.csv\"), index=False)\n",
    "\n",
    "# explainer_accuracies_df.to_csv(y, \"explainer_accuracies.csv\", index=False)\n",
    "explainer_accuracies_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  explainer  model  epochs     acc      auc        f1  precision    recall  \\\n",
       "0        IG  CMPNN       1  0.7475  0.84503  0.772693   0.707904  0.850537   \n",
       "1   GradCAM  CMPNN       1  0.7475  0.84503  0.772693   0.707904  0.850537   \n",
       "2    Random  CMPNN       1  0.7475  0.84503  0.772693   0.707904  0.850537   \n",
       "\n",
       "   Attribution AUROC  Attribution F1  Attribution ACC  Attribution Precision  \\\n",
       "0           0.948686        0.271034         0.826074               0.417503   \n",
       "1           0.946286        0.231217         0.815562               0.386618   \n",
       "2           0.495094        0.008616         0.809156               0.037847   \n",
       "\n",
       "   Attribution AUROC Mean  Attribution ACC Mean  \n",
       "0                0.901842              0.822130  \n",
       "1                0.893762              0.811085  \n",
       "2                0.497988              0.798624  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explainer</th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Attribution AUROC</th>\n",
       "      <th>Attribution F1</th>\n",
       "      <th>Attribution ACC</th>\n",
       "      <th>Attribution Precision</th>\n",
       "      <th>Attribution AUROC Mean</th>\n",
       "      <th>Attribution ACC Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IG</td>\n",
       "      <td>CMPNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.84503</td>\n",
       "      <td>0.772693</td>\n",
       "      <td>0.707904</td>\n",
       "      <td>0.850537</td>\n",
       "      <td>0.948686</td>\n",
       "      <td>0.271034</td>\n",
       "      <td>0.826074</td>\n",
       "      <td>0.417503</td>\n",
       "      <td>0.901842</td>\n",
       "      <td>0.822130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>CMPNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.84503</td>\n",
       "      <td>0.772693</td>\n",
       "      <td>0.707904</td>\n",
       "      <td>0.850537</td>\n",
       "      <td>0.946286</td>\n",
       "      <td>0.231217</td>\n",
       "      <td>0.815562</td>\n",
       "      <td>0.386618</td>\n",
       "      <td>0.893762</td>\n",
       "      <td>0.811085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random</td>\n",
       "      <td>CMPNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.84503</td>\n",
       "      <td>0.772693</td>\n",
       "      <td>0.707904</td>\n",
       "      <td>0.850537</td>\n",
       "      <td>0.495094</td>\n",
       "      <td>0.008616</td>\n",
       "      <td>0.809156</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>0.497988</td>\n",
       "      <td>0.798624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "86a613fd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.711445Z",
     "start_time": "2024-06-02T11:25:58.697079Z"
    }
   },
   "source": "\n",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ffab620e4ccaca85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.726736Z",
     "start_time": "2024-06-02T11:25:58.713456Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "def convert_from_test_to_real_idx(idx):\n",
    "    \"\"\"Converts the index used in the test set to the index in the whole dataset.\"\"\"    \n",
    "    smile = dataset.get_smiles_list(testing=True)[idx]\n",
    "    \n",
    "    data = dataset.whole_data_df \n",
    "    return data.loc[(data == smile).any(axis=1)].index[0]\n",
    "\n",
    "def convert_real_idx_to_test_idx(idx):\n",
    "    \"\"\"Converts an index from the big dataset to the one in the test set\"\"\"\n",
    "    ds = dataset.whole_data_df \n",
    "    ts = dataset.get_smiles_list()\n",
    "    smile = ds.iloc[idx]['SMILES']\n",
    "\n",
    "    return np.where(ts == smile)[0][0]"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.757688Z",
     "start_time": "2024-06-02T11:25:58.729737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_molecule(mol_idx:int, explainer='IG', threshold=1e-4, from_whole_data=False):\n",
    "    \"\"\"Splits the given molecule into explaining and non-explaining SMILES based on given explanation, returns those and the SMILES of the molecule. Threshold value is the same as in explainerExperiments.py visualization(). from_whole_data True if using idx in the whole dataset, False if looking by index in test set\"\"\"\n",
    "    \n",
    "    if from_whole_data:\n",
    "        smile = dataset.whole_data_df.SMILES.iat[mol_idx]\n",
    "        mol_idx = convert_real_idx_to_test_idx(mol_idx)\n",
    "    else:\n",
    "        # testing = True by default\n",
    "        smile = dataset.get_smiles_list(testing=True)[mol_idx]\n",
    "    \n",
    "    # atom importances depend on what explainer method is used, mol_idx is convenient\n",
    "    expl_idx = ATTRIBUTIONS.index(explainer)\n",
    "    a_importances = atom_importances[expl_idx][mol_idx]\n",
    "    \n",
    "    # print(type(a_importances), a_importances, type(a_importances[0]))\n",
    "    # print(\"threshold\", threshold, type(threshold))\n",
    "\n",
    "    original_mol = rdkit.Chem.RWMol(rdkit.Chem.MolFromSmiles(smile))\n",
    "     \n",
    "    non_explaining_atom_idxs = []\n",
    "    explaining_atom_idxs = []\n",
    "    for idx in range(len(original_mol.GetAtoms())):\n",
    "        if a_importances[idx] < threshold:\n",
    "            non_explaining_atom_idxs.append(idx)\n",
    "        else:\n",
    "            explaining_atom_idxs.append(idx)\n",
    "            \n",
    "    # reverse because removing atoms causes indices of others to shift\n",
    "    non_explaining_atom_idxs.reverse()\n",
    "    explaining_atom_idxs.reverse()\n",
    "    \n",
    "    # number of atoms in explanation vs whole molecule \n",
    "    exp_length = len(explaining_atom_idxs) / ( len(explaining_atom_idxs) + len(non_explaining_atom_idxs))\n",
    "    \n",
    "    # find (non)explaining bonds where at least one end is a non-explaining atom\n",
    "    non_explaining_bonds = []\n",
    "    explaining_bonds = []\n",
    "    \n",
    "    for bond in original_mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        \n",
    "        # if both end and start in explaining atoms, the edge is explaining \n",
    "        if (i and j) not in non_explaining_atom_idxs :\n",
    "            explaining_bonds.append((i, j))\n",
    "            explaining_bonds.append((j, i))\n",
    "        else:\n",
    "            non_explaining_bonds.append((i, j))\n",
    "            non_explaining_bonds.append((j, i))\n",
    "            \n",
    "            # remove i or j from explaining atoms \n",
    "            # so bonds between explaining and nonexplaining atoms are kept in non-explaining molecules\n",
    "            if i in explaining_atom_idxs: explaining_atom_idxs.remove(i)\n",
    "            if j in explaining_atom_idxs: explaining_atom_idxs.remove(j)\n",
    "    \n",
    "    # explaining molecule has non-explaining bonds and atoms removed\n",
    "    explaining_mol = copy.deepcopy(original_mol)\n",
    "    for (i, j) in non_explaining_bonds:\n",
    "        explaining_mol.RemoveBond(i, j)\n",
    "    \n",
    "    for idx in non_explaining_atom_idxs:\n",
    "        explaining_mol.RemoveAtom(idx)\n",
    "\n",
    "    explaining_smile = rdkit.Chem.MolToSmiles(explaining_mol)\n",
    "    \n",
    "    # comprehensiveness uses non-explaining atoms and edges\n",
    "    non_explaining_mol = copy.deepcopy(original_mol)\n",
    "    \n",
    "    for (i, j) in explaining_bonds:\n",
    "        non_explaining_mol.RemoveBond(i, j)\n",
    "\n",
    "    # remove explaining atoms    \n",
    "    for i in explaining_atom_idxs:\n",
    "        non_explaining_mol.RemoveAtom(i)\n",
    "    \n",
    "    non_explaining_smile = rdkit.Chem.MolToSmiles(non_explaining_mol)\n",
    "    \n",
    "    return smile, explaining_smile, non_explaining_smile, exp_length"
   ],
   "id": "9319bd0830aedaf5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.772612Z",
     "start_time": "2024-06-02T11:25:58.759646Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7db2f878314aefbc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "d2aaed81-856d-436e-b709-e74873673a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.788571Z",
     "start_time": "2024-06-02T11:25:58.777602Z"
    }
   },
   "source": [
    "s, e, n, m = split_molecule(137, from_whole_data=True)\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# print(s)\n",
    "# print(e)\n",
    "# print(n)\n",
    "# Draw.MolToImage(Chem.MolFromSmiles(s))\n",
    "# Draw.MolToImage(Chem.MolFromSmiles(e))\n",
    "# Draw.MolToImage(Chem.MolFromSmiles(n))\n",
    "# print(ATTRIBUTION)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "bd22e2c2-02cb-4660-be4f-2d556d4042e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.803537Z",
     "start_time": "2024-06-02T11:25:58.791565Z"
    }
   },
   "source": [
    "\n",
    "# Draw.MolToImage(Chem.MolFromSmiles(n))\n",
    "# 17 => 93.png"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "ebf3d2ee8dfcd116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.819526Z",
     "start_time": "2024-06-02T11:25:58.807519Z"
    }
   },
   "source": [
    "import torch\n",
    "from MolRep.Featurization.MPNN_embeddings import MolGraph, BatchMolGraph\n",
    "from rdkit.Chem import MolFromSmiles, rdmolops\n",
    "\n",
    "def tensors_to_device(smile, batch):\n",
    "    \"\"\"Sets nodes, edges, a2b, b2a and adjacency matrix tensors of a molecule to the device\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    adj = rdmolops.GetAdjacencyMatrix(MolFromSmiles(smile))\n",
    "    \n",
    "    features = {\n",
    "        'nodes' : batch.f_atoms, \n",
    "        'edges' : batch.f_bonds,\n",
    "        'a2b' : batch.a2b,\n",
    "        'b2a' : batch.b2a,\n",
    "        'adjacency' : torch.FloatTensor(adj) \n",
    "    }\n",
    "    \n",
    "    for i in features:\n",
    "        features[i].to(device)\n",
    "        \n",
    "    return features['nodes'], features['edges'], features['a2b'], features['b2a'], features['adjacency']"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "e2d35283cb961a64",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.834482Z",
     "start_time": "2024-06-02T11:25:58.822479Z"
    }
   },
   "source": [
    "import re\n",
    "def clean_smile(smile:str) -> str:\n",
    "    \"\"\"Takes a (fragmented) SMILES as input and returns concatenated valid fragments of it. Does nothing if input is already valid.\n",
    "    e.g: C.CC.F.O.n.n -> C.CC.F.O\n",
    "    \"\"\"\n",
    "    cs = \"\"\n",
    "    # 1. split n/explanations into a list\n",
    "    subm = smile.split('.')\n",
    "    \n",
    "    # 2. try to convert the pieces into a molgraph\n",
    "    # if success, append to a new string cs (cut string)\n",
    "    for (i, sm) in enumerate(subm): \n",
    "        try:\n",
    "            MolGraph(sm)\n",
    "            cs += sm\n",
    "            cs += '.'\n",
    "        except:\n",
    "            cs += '.'\n",
    "            continue\n",
    "\n",
    "    # remove repetitions and the first and last period from the string\n",
    "    cs = re.sub(\"\\.+\", \".\", cs)\n",
    "    # ReGeX from https://stackoverflow.com/a/3331982\n",
    "    cs = re.sub(\"\\.([^.]*)$\", \"\", cs)\n",
    "    cs = re.sub(\"(^\\.)\", \"\", cs)\n",
    "    return cs"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "790fcae9ee2dbea1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:25:58.849406Z",
     "start_time": "2024-06-02T11:25:58.836453Z"
    }
   },
   "source": [
    "def clear_gpu_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "EXPERIMENT_MODEL = MODELPATH"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "4d6c91327aefcf6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:28:34.926085Z",
     "start_time": "2024-06-02T11:28:34.898124Z"
    }
   },
   "source": [
    "def comp_and_suff(idx, explainer = 'IG', from_all_data=False, modified_formula=True) :\n",
    "    \"\"\"Calculates comprehensiveness and sufficiency for a molecule with index idx, given explanation e, returns an object with mol_idx, all the smiles (cleaned and uncleaned), predictions for everything, comprehensiveness and sufficiency, and proportion of explanation vs original molecule. from_all_data True if fetching smile from the whole set, False if from test set.\"\"\"\n",
    "    \n",
    "    # TODO move this out so no need to get the same model every time\n",
    "    model = explainer_experiment.get_model(dataset, other={'model_path':EXPERIMENT_MODEL})\n",
    "    model.eval() # set model to evaluation mode\n",
    "\n",
    "    smile, explaining_smile, non_explaining_smile, exp_length = split_molecule(idx, explainer, from_whole_data=from_all_data)\n",
    "    \n",
    "    # clean up the smiles, split may have created invalid molecules\n",
    "    clean_smiles = list(map(clean_smile, [smile, explaining_smile, non_explaining_smile]))\n",
    "\n",
    "    preds = []\n",
    "    for (i, cs) in enumerate(clean_smiles):\n",
    "        if cs == \"\": # don't predict empty strings\n",
    "            # if no non-explaining, then comp is f(g) = great, because the whole molecule explains the prediction!\n",
    "            # if no explaining, suff is f(g) = maybe good?, because there's nothing to explain why prediction was made?\n",
    "            \n",
    "            # none to predict to begin with != none being valid\n",
    "            if cs == [smile, explaining_smile, non_explaining_smile][i]:\n",
    "                preds.append([0]) # no (non)explaining to begin with is a-okay     \n",
    "            else:\n",
    "                preds.append([None]) # no valid strings after cleaning up less so\n",
    "            continue\n",
    "            \n",
    "        subpreds = []\n",
    "        \n",
    "        if modified_formula:\n",
    "            splits = cs.split('.')\n",
    "            for split in splits:\n",
    "            \n",
    "                # 3. convert s to molgraph\n",
    "                try:\n",
    "                    mol = MolGraph(split)\n",
    "                    g_input = BatchMolGraph( [mol])\n",
    "                    atoms, bonds, a2b, b2a, adjacency = tensors_to_device(cs, g_input)\n",
    "            \n",
    "                    with torch.no_grad():\n",
    "                        # TODO investigate None params?\n",
    "                        #   Args for mol2graph:\n",
    "                        # - mols: A list of SMILES or a list of RDKit molecules.\n",
    "                        # - atom_descriptors_batch: A list of 2D numpy array containing additional atom descriptors to featurize the molecule\n",
    "                        subpred = model([[split], None, None]).item()\n",
    "            \n",
    "                    subpreds.append(subpred)\n",
    "                except:\n",
    "                    # If model couldn't predict the subgraph for whatever weird reason\n",
    "                    # I don't know why this would happen, but evidently it does happen\n",
    "                    subpreds.append(None)\n",
    "        else:\n",
    "            try:\n",
    "                mol = MolGraph(cs)\n",
    "                g_input = BatchMolGraph( [mol])\n",
    "                atoms, bonds, a2b, b2a, adjacency = tensors_to_device(cs, g_input)\n",
    "        \n",
    "                with torch.no_grad():\n",
    "                    # TODO investigate None params?\n",
    "                    #   Args for mol2graph:\n",
    "                    # - mols: A list of SMILES or a list of RDKit molecules.\n",
    "                    # - atom_descriptors_batch: A list of 2D numpy array containing additional atom descriptors to featurize the molecule\n",
    "                    subpred = model([[cs], None, None]).item()\n",
    "        \n",
    "                subpreds.append(subpred)\n",
    "            except:\n",
    "                # If model couldn't predict the subgraph for whatever weird reason\n",
    "                # I don't know why this would happen, but evidently it does happen\n",
    "                subpreds.append(None)\n",
    "            \n",
    "        preds.append(subpreds)\n",
    "    \n",
    "    converted_idx = convert_from_test_to_real_idx(idx)\n",
    "    \n",
    "    try:\n",
    "        mol_pred = preds[0][0] # prediction of original molecule, there is only one so do nothing\n",
    "        \n",
    "        if modified_formula: \n",
    "            e_pred = None if preds[1] == [None] else sum(preds[1]) / len(preds[1]) # prediction of explaining molecules : take the mean\n",
    "            n_pred = None if preds[2] == [None] else sum(preds[2]) # prediction of non-explaining molecules : sum\n",
    "        else:\n",
    "            e_pred = None if preds[1] == [None] else preds[1][0]\n",
    "            n_pred = None if preds[2] == [None] else preds[2][0]\n",
    "        \n",
    "        # f = model prediction given a smile\n",
    "        # comp = f(smile) - f(non_explaining_smile)\n",
    "        # suff = f (smile) - f(explaining_smile)\n",
    "        \n",
    "        comp = mol_pred - n_pred if n_pred is not None else None\n",
    "        suff = mol_pred - e_pred if e_pred is not None else None\n",
    "        \n",
    "        result = {\n",
    "            \"explainer\" : explainer,\n",
    "            \"mol_idx\": idx if from_all_data else converted_idx,\n",
    "            \"smile\" : smile,\n",
    "            \"explaining_smile\" : explaining_smile,\n",
    "            \"clean_explanation\" : clean_smiles[1],\n",
    "            \"non_explaining_smile\" : non_explaining_smile,\n",
    "            \"clean_nonexplanation\": clean_smiles[2],\n",
    "            \"mol_pred\": mol_pred,\n",
    "            \"e_pred\": e_pred,\n",
    "            \"ne_pred\": n_pred,\n",
    "            \"comp\" : comp,\n",
    "            \"suff\" : suff,\n",
    "            \"expl length\": exp_length\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    except:\n",
    "        # print \n",
    "        print(preds, \" idx in dataset: \", converted_idx , \" idx in test set: \", idx)\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:28:35.900447Z",
     "start_time": "2024-06-02T11:28:35.397790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "van_3 = comp_and_suff(3, modified_formula=False, from_all_data=True) # mol 3 in whole set\n",
    "mod_3 = comp_and_suff(3, from_all_data=True)\n",
    "\n",
    "van_509 = comp_and_suff(509, modified_formula=False, from_all_data=True)\n",
    "mod_509 = comp_and_suff(509, from_all_data=True) \n",
    "\n",
    "# print(split_molecule(3, from_whole_data=False)) # mol idx is number 3 in test set i.e. mol 13\n",
    "# print(split_molecule(3, from_whole_data=True)) # mol idx is number 3 in whole set\n",
    "# Draw.MolToImage()"
   ],
   "id": "e87af8eace205048",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:28:38.075715Z",
     "start_time": "2024-06-02T11:28:38.053782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c = pd.DataFrame([van_3, mod_3, van_509, mod_509])\n",
    "c\n",
    "# print(van_3)\n",
    "# print(mod_3)"
   ],
   "id": "fcadf906349f859f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  explainer  mol_idx                                   smile  \\\n",
       "0        IG        3  CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]   \n",
       "1        IG        3  CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]   \n",
       "2        IG      509  C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F   \n",
       "3        IG      509  C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F   \n",
       "\n",
       "                   explaining_smile                 clean_explanation  \\\n",
       "0  O=CNc1ccc([N+](=O)[O-])c2ccccc12  O=CNc1ccc([N+](=O)[O-])c2ccccc12   \n",
       "1  O=CNc1ccc([N+](=O)[O-])c2ccccc12  O=CNc1ccc([N+](=O)[O-])c2ccccc12   \n",
       "2                     NC=O.c1ccccc1                     NC=O.c1ccccc1   \n",
       "3                     NC=O.c1ccccc1                     NC=O.c1ccccc1   \n",
       "\n",
       "      non_explaining_smile clean_nonexplanation  mol_pred    e_pred   ne_pred  \\\n",
       "0                    CC.CN                CC.CN  0.565568  0.572062  0.453750   \n",
       "1                    CC.CN                CC.CN  0.565568  0.572062  0.922270   \n",
       "2  CCN(C)Cc.C[C@@H]1CC1.cF          C[C@@H]1CC1  0.509846  0.567338  0.438039   \n",
       "3  CCN(C)Cc.C[C@@H]1CC1.cF          C[C@@H]1CC1  0.509846  0.535968  0.438039   \n",
       "\n",
       "       comp      suff  expl length  \n",
       "0  0.111818 -0.006494     0.888889  \n",
       "1 -0.356702 -0.006494     0.888889  \n",
       "2  0.071808 -0.057492     0.500000  \n",
       "3  0.071808 -0.026122     0.500000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explainer</th>\n",
       "      <th>mol_idx</th>\n",
       "      <th>smile</th>\n",
       "      <th>explaining_smile</th>\n",
       "      <th>clean_explanation</th>\n",
       "      <th>non_explaining_smile</th>\n",
       "      <th>clean_nonexplanation</th>\n",
       "      <th>mol_pred</th>\n",
       "      <th>e_pred</th>\n",
       "      <th>ne_pred</th>\n",
       "      <th>comp</th>\n",
       "      <th>suff</th>\n",
       "      <th>expl length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IG</td>\n",
       "      <td>3</td>\n",
       "      <td>CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]</td>\n",
       "      <td>O=CNc1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>O=CNc1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>CC.CN</td>\n",
       "      <td>CC.CN</td>\n",
       "      <td>0.565568</td>\n",
       "      <td>0.572062</td>\n",
       "      <td>0.453750</td>\n",
       "      <td>0.111818</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IG</td>\n",
       "      <td>3</td>\n",
       "      <td>CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]</td>\n",
       "      <td>O=CNc1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>O=CNc1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>CC.CN</td>\n",
       "      <td>CC.CN</td>\n",
       "      <td>0.565568</td>\n",
       "      <td>0.572062</td>\n",
       "      <td>0.922270</td>\n",
       "      <td>-0.356702</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IG</td>\n",
       "      <td>509</td>\n",
       "      <td>C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F</td>\n",
       "      <td>NC=O.c1ccccc1</td>\n",
       "      <td>NC=O.c1ccccc1</td>\n",
       "      <td>CCN(C)Cc.C[C@@H]1CC1.cF</td>\n",
       "      <td>C[C@@H]1CC1</td>\n",
       "      <td>0.509846</td>\n",
       "      <td>0.567338</td>\n",
       "      <td>0.438039</td>\n",
       "      <td>0.071808</td>\n",
       "      <td>-0.057492</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IG</td>\n",
       "      <td>509</td>\n",
       "      <td>C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F</td>\n",
       "      <td>NC=O.c1ccccc1</td>\n",
       "      <td>NC=O.c1ccccc1</td>\n",
       "      <td>CCN(C)Cc.C[C@@H]1CC1.cF</td>\n",
       "      <td>C[C@@H]1CC1</td>\n",
       "      <td>0.509846</td>\n",
       "      <td>0.535968</td>\n",
       "      <td>0.438039</td>\n",
       "      <td>0.071808</td>\n",
       "      <td>-0.026122</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "b5126cce8ec43d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:03:06.331339Z",
     "start_time": "2024-05-31T21:03:06.316379Z"
    }
   },
   "source": [
    "def comp_and_suff_data(explainer='IG', sample_size=2400):\n",
    "    \"\"\"Accumulates the comp and suff for all molecules within the test set of the provided dataset.\"\"\"\n",
    "    c_and_s = []\n",
    "    \n",
    "    n = min(sample_size, len(dataset.get_smiles_idxs(testing=True)))\n",
    "\n",
    "    # we only care about the index, because we're getting things by index in the test set\n",
    "    for i in range(n):\n",
    "        torch.cuda.empty_cache() # please be enough to allow things to run smoothly\n",
    "        vals = comp_and_suff(i, explainer)\n",
    "        c_and_s.append(vals)\n",
    "    return c_and_s\n",
    "\n",
    "\n",
    "# c = comp_and_suff_data(sample_size=10)\n",
    "# pd.DataFrame(c)"
   ],
   "outputs": [],
   "execution_count": 136
  },
  {
   "cell_type": "code",
   "id": "3557ada17b40b13c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:03:40.526769Z",
     "start_time": "2024-05-31T21:03:06.343306Z"
    }
   },
   "source": [
    "# TODO 2 further work\n",
    "# save results of comp-suff for transparency\n",
    "# use a different explainer on the model\n",
    "# save those results\n",
    "\n",
    "def comp_and_suff_for_all_explainers(explainers, sample_size=100):\n",
    "    \"\"\"Calculates comp and suff for all explainers, given a list of explainers and a full matrix of atom importances.\"\"\"\n",
    "    comps = []\n",
    "    \n",
    "    for (i, explainer) in enumerate(explainers):\n",
    "        torch.cuda.empty_cache() # please be enough to allow things to run smoothly\n",
    "        # print(i, explainer)\n",
    "        \n",
    "        comp = comp_and_suff_data(explainer=explainer, sample_size=sample_size)\n",
    "        \n",
    "        comps.append(comp)\n",
    "    return comps\n",
    "\n",
    "c_and_s = comp_and_suff_for_all_explainers(ATTRIBUTIONS, sample_size=100)\n",
    "# c_and_s = comp_and_suff_data(dataset, 'IG', sample_size=60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n",
      "Moving model to cuda\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:09:18.749383Z",
     "start_time": "2024-05-31T21:09:18.721457Z"
    }
   },
   "cell_type": "code",
   "source": "pd.DataFrame(c_and_s[0])",
   "id": "da06574ffbb0bd96",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   explainer  mol_idx                                              smile  \\\n",
       "0         IG        3             CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]   \n",
       "1         IG        9                 COC[C@H](C(=O)N)NC(=O)Cc1cccc(c1)F   \n",
       "2         IG       10            c1cc(cc(c1)F)CNc1ccc(cc1)C(=O)NC1CCOCC1   \n",
       "3         IG       13                        Cn1cncc1CCNC(=O)c1cc(cnc1)F   \n",
       "4         IG       17  CN(CC[C@@H](c1ccccc1)O)C(=O)[C@@H]1CC[N@H+](CC...   \n",
       "..       ...      ...                                                ...   \n",
       "95        IG      496        C[C@@H](c1ccc(cc1)n1cncn1)NC(=O)NCCN1CCOCC1   \n",
       "96        IG      497      Cn1c(nnc1[C@H]1CCC[N@H+](C1)C1CCCCC1)Cn1ccnc1   \n",
       "97        IG      498              Cc1ncc(s1)[C@@H](C)[NH2+][C@H](C)CCSC   \n",
       "98        IG      506    CCOC(=O)[C@@H]1C[N@@H+](C[C@@H]1C(=O)c1ccccc1)C   \n",
       "99        IG      509             C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F   \n",
       "\n",
       "                    explaining_smile                 clean_explanation  \\\n",
       "0   O=CNc1ccc([N+](=O)[O-])c2ccccc12  O=CNc1ccc([N+](=O)[O-])c2ccccc12   \n",
       "1                     CN.CN.c1ccccc1                             CN.CN   \n",
       "2             NCc1ccc(N)cc1.c1ccccc1                     NCc1ccc(N)cc1   \n",
       "3                 cccc(c)C(N)=O.ccnc                                     \n",
       "4                      C.CN.c1ccccc1                              C.CN   \n",
       "..                               ...                               ...   \n",
       "95                 NCN.c.cn-c1ccccc1                               NCN   \n",
       "96                          ccnc.cnc                                     \n",
       "97                              c.cc                                     \n",
       "98                       C.Cc1ccccc1                                 C   \n",
       "99                     NC=O.c1ccccc1                              NC=O   \n",
       "\n",
       "                        non_explaining_smile clean_nonexplanation  mol_pred  \\\n",
       "0                                      CC.CN                   CC  0.565568   \n",
       "1                           C=O.CC=O.CCOC.cF        C=O.CC=O.CCOC  0.518624   \n",
       "2                        C=O.NC1CCOCC1.cC.cF        C=O.NC1CCOCC1  0.540191   \n",
       "3                            Cn.cCC.cF.cn.cn                       0.546673   \n",
       "4         C=O.CNCCCO.C[N@H+]1CC[C@H](C=O)CC1           C=O.CNCCCO  0.489150   \n",
       "..                                       ...                  ...       ...   \n",
       "95                  C=O.CC.NCCN1CCOCC1.cn.cn   C=O.CC.NCCN1CCOCC1  0.517687   \n",
       "96  Ccnn.Cn.c[C@H]1CCC[N@@H+](C2CCCCC2)C1.cn                       0.475073   \n",
       "97         CSCC[C@@H](C)[NH2+][C@H](C)cs.Ccn                       0.476645   \n",
       "98           C=O.CCO.C[N@@H+]1CC[C@H](C=O)C1              C=O.CCO  0.504132   \n",
       "99                   CCN(C)Cc.C[C@@H]1CC1.cF          C[C@@H]1CC1  0.509846   \n",
       "\n",
       "      e_pred   ne_pred      comp      suff  expl length  \n",
       "0   0.572062  0.459984  0.105584 -0.006494     0.888889  \n",
       "1   0.462286  1.397677 -0.879052  0.056338     0.555556  \n",
       "2   0.562552  0.907459 -0.367268 -0.022361     0.625000  \n",
       "3        NaN       NaN       NaN       NaN     0.666667  \n",
       "4   0.467179  0.917614 -0.428464  0.021971     0.375000  \n",
       "..       ...       ...       ...       ...          ...  \n",
       "95  0.454082  1.367905 -0.850218  0.063605     0.480000  \n",
       "96       NaN       NaN       NaN       NaN     0.291667  \n",
       "97       NaN       NaN       NaN       NaN     0.200000  \n",
       "98  0.472073  0.927723 -0.423591  0.032059     0.421053  \n",
       "99  0.490961  0.438039  0.071808  0.018885     0.500000  \n",
       "\n",
       "[100 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explainer</th>\n",
       "      <th>mol_idx</th>\n",
       "      <th>smile</th>\n",
       "      <th>explaining_smile</th>\n",
       "      <th>clean_explanation</th>\n",
       "      <th>non_explaining_smile</th>\n",
       "      <th>clean_nonexplanation</th>\n",
       "      <th>mol_pred</th>\n",
       "      <th>e_pred</th>\n",
       "      <th>ne_pred</th>\n",
       "      <th>comp</th>\n",
       "      <th>suff</th>\n",
       "      <th>expl length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IG</td>\n",
       "      <td>3</td>\n",
       "      <td>CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]</td>\n",
       "      <td>O=CNc1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>O=CNc1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>CC.CN</td>\n",
       "      <td>CC</td>\n",
       "      <td>0.565568</td>\n",
       "      <td>0.572062</td>\n",
       "      <td>0.459984</td>\n",
       "      <td>0.105584</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IG</td>\n",
       "      <td>9</td>\n",
       "      <td>COC[C@H](C(=O)N)NC(=O)Cc1cccc(c1)F</td>\n",
       "      <td>CN.CN.c1ccccc1</td>\n",
       "      <td>CN.CN</td>\n",
       "      <td>C=O.CC=O.CCOC.cF</td>\n",
       "      <td>C=O.CC=O.CCOC</td>\n",
       "      <td>0.518624</td>\n",
       "      <td>0.462286</td>\n",
       "      <td>1.397677</td>\n",
       "      <td>-0.879052</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IG</td>\n",
       "      <td>10</td>\n",
       "      <td>c1cc(cc(c1)F)CNc1ccc(cc1)C(=O)NC1CCOCC1</td>\n",
       "      <td>NCc1ccc(N)cc1.c1ccccc1</td>\n",
       "      <td>NCc1ccc(N)cc1</td>\n",
       "      <td>C=O.NC1CCOCC1.cC.cF</td>\n",
       "      <td>C=O.NC1CCOCC1</td>\n",
       "      <td>0.540191</td>\n",
       "      <td>0.562552</td>\n",
       "      <td>0.907459</td>\n",
       "      <td>-0.367268</td>\n",
       "      <td>-0.022361</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IG</td>\n",
       "      <td>13</td>\n",
       "      <td>Cn1cncc1CCNC(=O)c1cc(cnc1)F</td>\n",
       "      <td>cccc(c)C(N)=O.ccnc</td>\n",
       "      <td></td>\n",
       "      <td>Cn.cCC.cF.cn.cn</td>\n",
       "      <td></td>\n",
       "      <td>0.546673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IG</td>\n",
       "      <td>17</td>\n",
       "      <td>CN(CC[C@@H](c1ccccc1)O)C(=O)[C@@H]1CC[N@H+](CC...</td>\n",
       "      <td>C.CN.c1ccccc1</td>\n",
       "      <td>C.CN</td>\n",
       "      <td>C=O.CNCCCO.C[N@H+]1CC[C@H](C=O)CC1</td>\n",
       "      <td>C=O.CNCCCO</td>\n",
       "      <td>0.489150</td>\n",
       "      <td>0.467179</td>\n",
       "      <td>0.917614</td>\n",
       "      <td>-0.428464</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>IG</td>\n",
       "      <td>496</td>\n",
       "      <td>C[C@@H](c1ccc(cc1)n1cncn1)NC(=O)NCCN1CCOCC1</td>\n",
       "      <td>NCN.c.cn-c1ccccc1</td>\n",
       "      <td>NCN</td>\n",
       "      <td>C=O.CC.NCCN1CCOCC1.cn.cn</td>\n",
       "      <td>C=O.CC.NCCN1CCOCC1</td>\n",
       "      <td>0.517687</td>\n",
       "      <td>0.454082</td>\n",
       "      <td>1.367905</td>\n",
       "      <td>-0.850218</td>\n",
       "      <td>0.063605</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>IG</td>\n",
       "      <td>497</td>\n",
       "      <td>Cn1c(nnc1[C@H]1CCC[N@H+](C1)C1CCCCC1)Cn1ccnc1</td>\n",
       "      <td>ccnc.cnc</td>\n",
       "      <td></td>\n",
       "      <td>Ccnn.Cn.c[C@H]1CCC[N@@H+](C2CCCCC2)C1.cn</td>\n",
       "      <td></td>\n",
       "      <td>0.475073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>IG</td>\n",
       "      <td>498</td>\n",
       "      <td>Cc1ncc(s1)[C@@H](C)[NH2+][C@H](C)CCSC</td>\n",
       "      <td>c.cc</td>\n",
       "      <td></td>\n",
       "      <td>CSCC[C@@H](C)[NH2+][C@H](C)cs.Ccn</td>\n",
       "      <td></td>\n",
       "      <td>0.476645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>IG</td>\n",
       "      <td>506</td>\n",
       "      <td>CCOC(=O)[C@@H]1C[N@@H+](C[C@@H]1C(=O)c1ccccc1)C</td>\n",
       "      <td>C.Cc1ccccc1</td>\n",
       "      <td>C</td>\n",
       "      <td>C=O.CCO.C[N@@H+]1CC[C@H](C=O)C1</td>\n",
       "      <td>C=O.CCO</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.472073</td>\n",
       "      <td>0.927723</td>\n",
       "      <td>-0.423591</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>IG</td>\n",
       "      <td>509</td>\n",
       "      <td>C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F</td>\n",
       "      <td>NC=O.c1ccccc1</td>\n",
       "      <td>NC=O</td>\n",
       "      <td>CCN(C)Cc.C[C@@H]1CC1.cF</td>\n",
       "      <td>C[C@@H]1CC1</td>\n",
       "      <td>0.509846</td>\n",
       "      <td>0.490961</td>\n",
       "      <td>0.438039</td>\n",
       "      <td>0.071808</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:09:41.902208Z",
     "start_time": "2024-05-31T21:09:41.874282Z"
    }
   },
   "cell_type": "code",
   "source": "pd.DataFrame(c_and_s[1])",
   "id": "b992ac39f64b9975",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   explainer  mol_idx                                              smile  \\\n",
       "0    GradCAM        3             CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]   \n",
       "1    GradCAM        9                 COC[C@H](C(=O)N)NC(=O)Cc1cccc(c1)F   \n",
       "2    GradCAM       10            c1cc(cc(c1)F)CNc1ccc(cc1)C(=O)NC1CCOCC1   \n",
       "3    GradCAM       13                        Cn1cncc1CCNC(=O)c1cc(cnc1)F   \n",
       "4    GradCAM       17  CN(CC[C@@H](c1ccccc1)O)C(=O)[C@@H]1CC[N@H+](CC...   \n",
       "..       ...      ...                                                ...   \n",
       "95   GradCAM      496        C[C@@H](c1ccc(cc1)n1cncn1)NC(=O)NCCN1CCOCC1   \n",
       "96   GradCAM      497      Cn1c(nnc1[C@H]1CCC[N@H+](C1)C1CCCCC1)Cn1ccnc1   \n",
       "97   GradCAM      498              Cc1ncc(s1)[C@@H](C)[NH2+][C@H](C)CCSC   \n",
       "98   GradCAM      506    CCOC(=O)[C@@H]1C[N@@H+](C[C@@H]1C(=O)c1ccccc1)C   \n",
       "99   GradCAM      509             C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F   \n",
       "\n",
       "                    explaining_smile                 clean_explanation  \\\n",
       "0   O=CNc1ccc([N+](=O)[O-])c2ccccc12  O=CNc1ccc([N+](=O)[O-])c2ccccc12   \n",
       "1                 NC=O.NC=O.c1ccccc1                         NC=O.NC=O   \n",
       "2         NC(=O)c1ccc(N)cc1.c1ccccc1                 NC(=O)c1ccc(N)cc1   \n",
       "3                 cccc(c)C(N)=O.ccnc                                     \n",
       "4               NC=O.NC=O.O.c1ccccc1                       NC=O.NC=O.O   \n",
       "..                               ...                               ...   \n",
       "95             NC(N)=O.c.cn-c1ccccc1                           NC(N)=O   \n",
       "96                          ccnc.cnc                                     \n",
       "97                              c.cc                                     \n",
       "98                   C=O.O=Cc1ccccc1                               C=O   \n",
       "99                  NC(N)=O.c1ccccc1                           NC(N)=O   \n",
       "\n",
       "                        non_explaining_smile clean_nonexplanation  mol_pred  \\\n",
       "0                                      CC.CN                   CC  0.565568   \n",
       "1                                 CC.CCOC.cF              CC.CCOC  0.518624   \n",
       "2                            NC1CCOCC1.cC.cF            NC1CCOCC1  0.540191   \n",
       "3                            Cn.cCC.cF.cn.cn                       0.546673   \n",
       "4                CCCNC.C[C@H]1CC[N@H+](C)CC1                CCCNC  0.489150   \n",
       "..                                       ...                  ...       ...   \n",
       "95                      CC.NCCN1CCOCC1.cn.cn       CC.NCCN1CCOCC1  0.517687   \n",
       "96  Ccnn.Cn.c[C@H]1CCC[N@@H+](C2CCCCC2)C1.cn                       0.475073   \n",
       "97         CSCC[C@@H](C)[NH2+][C@H](C)cs.Ccn                       0.476645   \n",
       "98                 CCO.C[C@H]1CC[N@@H+](C)C1                  CCO  0.504132   \n",
       "99                     CCN.C[C@@H]1CC1.cC.cF      CCN.C[C@@H]1CC1  0.509846   \n",
       "\n",
       "      e_pred   ne_pred      comp      suff  expl length  \n",
       "0   0.572062  0.459984  0.105584 -0.006494     0.888889  \n",
       "1   0.490961  0.906409 -0.387785  0.027663     0.666667  \n",
       "2   0.567293  0.431738  0.108453 -0.027102     0.666667  \n",
       "3        NaN       NaN       NaN       NaN     0.666667  \n",
       "4   0.484110  0.443845  0.045306  0.005041     0.541667  \n",
       "..       ...       ...       ...       ...          ...  \n",
       "95  0.490683  0.892184 -0.374497  0.027004     0.520000  \n",
       "96       NaN       NaN       NaN       NaN     0.291667  \n",
       "97       NaN       NaN       NaN       NaN     0.200000  \n",
       "98  0.475721  0.452002  0.052130  0.028411     0.526316  \n",
       "99  0.490683  0.890154 -0.380307  0.019163     0.555556  \n",
       "\n",
       "[100 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explainer</th>\n",
       "      <th>mol_idx</th>\n",
       "      <th>smile</th>\n",
       "      <th>explaining_smile</th>\n",
       "      <th>clean_explanation</th>\n",
       "      <th>non_explaining_smile</th>\n",
       "      <th>clean_nonexplanation</th>\n",
       "      <th>mol_pred</th>\n",
       "      <th>e_pred</th>\n",
       "      <th>ne_pred</th>\n",
       "      <th>comp</th>\n",
       "      <th>suff</th>\n",
       "      <th>expl length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>3</td>\n",
       "      <td>CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]</td>\n",
       "      <td>O=CNc1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>O=CNc1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>CC.CN</td>\n",
       "      <td>CC</td>\n",
       "      <td>0.565568</td>\n",
       "      <td>0.572062</td>\n",
       "      <td>0.459984</td>\n",
       "      <td>0.105584</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>9</td>\n",
       "      <td>COC[C@H](C(=O)N)NC(=O)Cc1cccc(c1)F</td>\n",
       "      <td>NC=O.NC=O.c1ccccc1</td>\n",
       "      <td>NC=O.NC=O</td>\n",
       "      <td>CC.CCOC.cF</td>\n",
       "      <td>CC.CCOC</td>\n",
       "      <td>0.518624</td>\n",
       "      <td>0.490961</td>\n",
       "      <td>0.906409</td>\n",
       "      <td>-0.387785</td>\n",
       "      <td>0.027663</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>10</td>\n",
       "      <td>c1cc(cc(c1)F)CNc1ccc(cc1)C(=O)NC1CCOCC1</td>\n",
       "      <td>NC(=O)c1ccc(N)cc1.c1ccccc1</td>\n",
       "      <td>NC(=O)c1ccc(N)cc1</td>\n",
       "      <td>NC1CCOCC1.cC.cF</td>\n",
       "      <td>NC1CCOCC1</td>\n",
       "      <td>0.540191</td>\n",
       "      <td>0.567293</td>\n",
       "      <td>0.431738</td>\n",
       "      <td>0.108453</td>\n",
       "      <td>-0.027102</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>13</td>\n",
       "      <td>Cn1cncc1CCNC(=O)c1cc(cnc1)F</td>\n",
       "      <td>cccc(c)C(N)=O.ccnc</td>\n",
       "      <td></td>\n",
       "      <td>Cn.cCC.cF.cn.cn</td>\n",
       "      <td></td>\n",
       "      <td>0.546673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>17</td>\n",
       "      <td>CN(CC[C@@H](c1ccccc1)O)C(=O)[C@@H]1CC[N@H+](CC...</td>\n",
       "      <td>NC=O.NC=O.O.c1ccccc1</td>\n",
       "      <td>NC=O.NC=O.O</td>\n",
       "      <td>CCCNC.C[C@H]1CC[N@H+](C)CC1</td>\n",
       "      <td>CCCNC</td>\n",
       "      <td>0.489150</td>\n",
       "      <td>0.484110</td>\n",
       "      <td>0.443845</td>\n",
       "      <td>0.045306</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>496</td>\n",
       "      <td>C[C@@H](c1ccc(cc1)n1cncn1)NC(=O)NCCN1CCOCC1</td>\n",
       "      <td>NC(N)=O.c.cn-c1ccccc1</td>\n",
       "      <td>NC(N)=O</td>\n",
       "      <td>CC.NCCN1CCOCC1.cn.cn</td>\n",
       "      <td>CC.NCCN1CCOCC1</td>\n",
       "      <td>0.517687</td>\n",
       "      <td>0.490683</td>\n",
       "      <td>0.892184</td>\n",
       "      <td>-0.374497</td>\n",
       "      <td>0.027004</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>497</td>\n",
       "      <td>Cn1c(nnc1[C@H]1CCC[N@H+](C1)C1CCCCC1)Cn1ccnc1</td>\n",
       "      <td>ccnc.cnc</td>\n",
       "      <td></td>\n",
       "      <td>Ccnn.Cn.c[C@H]1CCC[N@@H+](C2CCCCC2)C1.cn</td>\n",
       "      <td></td>\n",
       "      <td>0.475073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>498</td>\n",
       "      <td>Cc1ncc(s1)[C@@H](C)[NH2+][C@H](C)CCSC</td>\n",
       "      <td>c.cc</td>\n",
       "      <td></td>\n",
       "      <td>CSCC[C@@H](C)[NH2+][C@H](C)cs.Ccn</td>\n",
       "      <td></td>\n",
       "      <td>0.476645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>506</td>\n",
       "      <td>CCOC(=O)[C@@H]1C[N@@H+](C[C@@H]1C(=O)c1ccccc1)C</td>\n",
       "      <td>C=O.O=Cc1ccccc1</td>\n",
       "      <td>C=O</td>\n",
       "      <td>CCO.C[C@H]1CC[N@@H+](C)C1</td>\n",
       "      <td>CCO</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.475721</td>\n",
       "      <td>0.452002</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>509</td>\n",
       "      <td>C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F</td>\n",
       "      <td>NC(N)=O.c1ccccc1</td>\n",
       "      <td>NC(N)=O</td>\n",
       "      <td>CCN.C[C@@H]1CC1.cC.cF</td>\n",
       "      <td>CCN.C[C@@H]1CC1</td>\n",
       "      <td>0.509846</td>\n",
       "      <td>0.490683</td>\n",
       "      <td>0.890154</td>\n",
       "      <td>-0.380307</td>\n",
       "      <td>0.019163</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:09:42.387907Z",
     "start_time": "2024-05-31T21:09:42.362976Z"
    }
   },
   "cell_type": "code",
   "source": "pd.DataFrame(c_and_s[2])",
   "id": "f4d36dd3cdedc7cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   explainer  mol_idx                                              smile  \\\n",
       "0     Random        3             CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]   \n",
       "1     Random        9                 COC[C@H](C(=O)N)NC(=O)Cc1cccc(c1)F   \n",
       "2     Random       10            c1cc(cc(c1)F)CNc1ccc(cc1)C(=O)NC1CCOCC1   \n",
       "3     Random       13                        Cn1cncc1CCNC(=O)c1cc(cnc1)F   \n",
       "4     Random       17  CN(CC[C@@H](c1ccccc1)O)C(=O)[C@@H]1CC[N@H+](CC...   \n",
       "..       ...      ...                                                ...   \n",
       "95    Random      496        C[C@@H](c1ccc(cc1)n1cncn1)NC(=O)NCCN1CCOCC1   \n",
       "96    Random      497      Cn1c(nnc1[C@H]1CCC[N@H+](C1)C1CCCCC1)Cn1ccnc1   \n",
       "97    Random      498              Cc1ncc(s1)[C@@H](C)[NH2+][C@H](C)CCSC   \n",
       "98    Random      506    CCOC(=O)[C@@H]1C[N@@H+](C[C@@H]1C(=O)c1ccccc1)C   \n",
       "99    Random      509             C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F   \n",
       "\n",
       "                                     explaining_smile  \\\n",
       "0              CC(=O)N(C)c1ccc([N+](=O)[O-])c2ccccc12   \n",
       "1                      COC[C@H](CN)NC(=O)Cc1cccc(F)c1   \n",
       "2               O=C(NC1CCOCC1)c1ccc(NCc2cccc(F)c2)cc1   \n",
       "3                         Cn1cncc1CCNC(=O)c1cncc(F)c1   \n",
       "4   CN(CC[C@H](O)c1ccccc1)C(=O)[C@H]1CC[N@H+](CC(N...   \n",
       "..                                                ...   \n",
       "95        C[C@H](NC(=O)NCCN1CCOCC1)c1ccc(-n2cncn2)cc1   \n",
       "96     Cn1c(Cn2ccnc2)nnc1[C@H]1CCC[N@@H+](C2CCCCC2)C1   \n",
       "97              CSCC[C@@H](C)[NH2+][C@H](C)c1cnc(C)s1   \n",
       "98     CCOC(=O)[C@@H]1C[N@H+](C)C[C@@H]1C(=O)c1ccccc1   \n",
       "99             C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(F)ccc2C1   \n",
       "\n",
       "                                    clean_explanation non_explaining_smile  \\\n",
       "0              CC(=O)N(C)c1ccc([N+](=O)[O-])c2ccccc12                        \n",
       "1                      COC[C@H](CN)NC(=O)Cc1cccc(F)c1                  C=O   \n",
       "2               O=C(NC1CCOCC1)c1ccc(NCc2cccc(F)c2)cc1                        \n",
       "3                         Cn1cncc1CCNC(=O)c1cncc(F)c1                        \n",
       "4   CN(CC[C@H](O)c1ccccc1)C(=O)[C@H]1CC[N@H+](CC(N...                        \n",
       "..                                                ...                  ...   \n",
       "95        C[C@H](NC(=O)NCCN1CCOCC1)c1ccc(-n2cncn2)cc1                        \n",
       "96     Cn1c(Cn2ccnc2)nnc1[C@H]1CCC[N@@H+](C2CCCCC2)C1                        \n",
       "97              CSCC[C@@H](C)[NH2+][C@H](C)c1cnc(C)s1                        \n",
       "98     CCOC(=O)[C@@H]1C[N@H+](C)C[C@@H]1C(=O)c1ccccc1                        \n",
       "99             C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(F)ccc2C1                        \n",
       "\n",
       "   clean_nonexplanation  mol_pred    e_pred   ne_pred      comp      suff  \\\n",
       "0                        0.565568  0.563076  0.000000  0.565568  0.002492   \n",
       "1                   C=O  0.518624  0.511699  0.475721  0.042903  0.006926   \n",
       "2                        0.540191  0.538274  0.000000  0.540191  0.001917   \n",
       "3                        0.546673  0.545323  0.000000  0.546673  0.001350   \n",
       "4                        0.489150  0.490564  0.000000  0.489150 -0.001413   \n",
       "..                  ...       ...       ...       ...       ...       ...   \n",
       "95                       0.517687  0.512078  0.000000  0.517687  0.005609   \n",
       "96                       0.475073  0.481153  0.000000  0.475073 -0.006080   \n",
       "97                       0.476645  0.475088  0.000000  0.476645  0.001557   \n",
       "98                       0.504132  0.500708  0.000000  0.504132  0.003424   \n",
       "99                       0.509846  0.508607  0.000000  0.509846  0.001239   \n",
       "\n",
       "    expl length  \n",
       "0      1.000000  \n",
       "1      0.944444  \n",
       "2      1.000000  \n",
       "3      1.000000  \n",
       "4      1.000000  \n",
       "..          ...  \n",
       "95     1.000000  \n",
       "96     1.000000  \n",
       "97     1.000000  \n",
       "98     1.000000  \n",
       "99     1.000000  \n",
       "\n",
       "[100 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explainer</th>\n",
       "      <th>mol_idx</th>\n",
       "      <th>smile</th>\n",
       "      <th>explaining_smile</th>\n",
       "      <th>clean_explanation</th>\n",
       "      <th>non_explaining_smile</th>\n",
       "      <th>clean_nonexplanation</th>\n",
       "      <th>mol_pred</th>\n",
       "      <th>e_pred</th>\n",
       "      <th>ne_pred</th>\n",
       "      <th>comp</th>\n",
       "      <th>suff</th>\n",
       "      <th>expl length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random</td>\n",
       "      <td>3</td>\n",
       "      <td>CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]</td>\n",
       "      <td>CC(=O)N(C)c1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>CC(=O)N(C)c1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.565568</td>\n",
       "      <td>0.563076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565568</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>9</td>\n",
       "      <td>COC[C@H](C(=O)N)NC(=O)Cc1cccc(c1)F</td>\n",
       "      <td>COC[C@H](CN)NC(=O)Cc1cccc(F)c1</td>\n",
       "      <td>COC[C@H](CN)NC(=O)Cc1cccc(F)c1</td>\n",
       "      <td>C=O</td>\n",
       "      <td>C=O</td>\n",
       "      <td>0.518624</td>\n",
       "      <td>0.511699</td>\n",
       "      <td>0.475721</td>\n",
       "      <td>0.042903</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random</td>\n",
       "      <td>10</td>\n",
       "      <td>c1cc(cc(c1)F)CNc1ccc(cc1)C(=O)NC1CCOCC1</td>\n",
       "      <td>O=C(NC1CCOCC1)c1ccc(NCc2cccc(F)c2)cc1</td>\n",
       "      <td>O=C(NC1CCOCC1)c1ccc(NCc2cccc(F)c2)cc1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.540191</td>\n",
       "      <td>0.538274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540191</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random</td>\n",
       "      <td>13</td>\n",
       "      <td>Cn1cncc1CCNC(=O)c1cc(cnc1)F</td>\n",
       "      <td>Cn1cncc1CCNC(=O)c1cncc(F)c1</td>\n",
       "      <td>Cn1cncc1CCNC(=O)c1cncc(F)c1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.546673</td>\n",
       "      <td>0.545323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546673</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random</td>\n",
       "      <td>17</td>\n",
       "      <td>CN(CC[C@@H](c1ccccc1)O)C(=O)[C@@H]1CC[N@H+](CC...</td>\n",
       "      <td>CN(CC[C@H](O)c1ccccc1)C(=O)[C@H]1CC[N@H+](CC(N...</td>\n",
       "      <td>CN(CC[C@H](O)c1ccccc1)C(=O)[C@H]1CC[N@H+](CC(N...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.489150</td>\n",
       "      <td>0.490564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489150</td>\n",
       "      <td>-0.001413</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Random</td>\n",
       "      <td>496</td>\n",
       "      <td>C[C@@H](c1ccc(cc1)n1cncn1)NC(=O)NCCN1CCOCC1</td>\n",
       "      <td>C[C@H](NC(=O)NCCN1CCOCC1)c1ccc(-n2cncn2)cc1</td>\n",
       "      <td>C[C@H](NC(=O)NCCN1CCOCC1)c1ccc(-n2cncn2)cc1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.517687</td>\n",
       "      <td>0.512078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517687</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Random</td>\n",
       "      <td>497</td>\n",
       "      <td>Cn1c(nnc1[C@H]1CCC[N@H+](C1)C1CCCCC1)Cn1ccnc1</td>\n",
       "      <td>Cn1c(Cn2ccnc2)nnc1[C@H]1CCC[N@@H+](C2CCCCC2)C1</td>\n",
       "      <td>Cn1c(Cn2ccnc2)nnc1[C@H]1CCC[N@@H+](C2CCCCC2)C1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.475073</td>\n",
       "      <td>0.481153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475073</td>\n",
       "      <td>-0.006080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Random</td>\n",
       "      <td>498</td>\n",
       "      <td>Cc1ncc(s1)[C@@H](C)[NH2+][C@H](C)CCSC</td>\n",
       "      <td>CSCC[C@@H](C)[NH2+][C@H](C)c1cnc(C)s1</td>\n",
       "      <td>CSCC[C@@H](C)[NH2+][C@H](C)c1cnc(C)s1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.476645</td>\n",
       "      <td>0.475088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476645</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Random</td>\n",
       "      <td>506</td>\n",
       "      <td>CCOC(=O)[C@@H]1C[N@@H+](C[C@@H]1C(=O)c1ccccc1)C</td>\n",
       "      <td>CCOC(=O)[C@@H]1C[N@H+](C)C[C@@H]1C(=O)c1ccccc1</td>\n",
       "      <td>CCOC(=O)[C@@H]1C[N@H+](C)C[C@@H]1C(=O)c1ccccc1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.500708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Random</td>\n",
       "      <td>509</td>\n",
       "      <td>C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F</td>\n",
       "      <td>C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(F)ccc2C1</td>\n",
       "      <td>C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(F)ccc2C1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.509846</td>\n",
       "      <td>0.508607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509846</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:03:40.777103Z",
     "start_time": "2024-05-31T21:03:40.559683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clear_gpu_memory()\n",
    "\n",
    "# Cc1ccc(cc1)c1nc(c(nn1)C)Sc1cccc(c1)C(F)(F)F\n",
    "# c = comp_and_suff(137, convert_idx=False)\n",
    "# print(c)\n",
    "# \n",
    "# s , e, n, _ = split_molecule(137, convert_idx=False)\n",
    "# print(s, e, n, convert_from_test_to_real_idx(137))\n",
    "# clean_smile(n)\n",
    "# print(convert_real_idx_to_test_idx(11815))\n",
    "# s, e, n, m = split_molecule(11815, explainer='IG',convert_idx=True)\n",
    "# print(s, m)\n",
    "\n",
    "# Draw.MolToImage(MolFromSmiles(s))"
   ],
   "id": "a4afefaa-2d6e-4c9c-b544-3bee1c8aa60c",
   "outputs": [],
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "id": "f863193e8bc3725f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:47:34.279402Z",
     "start_time": "2024-06-01T13:47:34.258425Z"
    }
   },
   "source": [
    "def avg_comp_and_suff(d):\n",
    "    \"\"\"Calculates the average comp and suff for a list of data. Returns the original data length, avg comp and suff, and how many samples were used to calculate them.\"\"\"\n",
    "\n",
    "    c, n, s, m, l = 0, 0, 0, 0, 0\n",
    "    \n",
    "    for i in range(len(d)):\n",
    "        item = d[i]\n",
    "        mol_pred = item.get('mol_pred')\n",
    "        e_pred = item.get('e_pred')\n",
    "        ne_pred = item.get('ne_pred')\n",
    "        lgt = item.get('expl length')\n",
    "        \n",
    "        l += lgt if lgt is not None else 0\n",
    "        \n",
    "        # print(i, mol_pred, e_pred, ne_pred)\n",
    "\n",
    "        if ne_pred is not None:\n",
    "            # proportion of comprehensiveness to mol prediction\n",
    "            c += (abs (item.get('comp') / mol_pred) )\n",
    "            n += 1\n",
    "\n",
    "        if e_pred is not None:\n",
    "            # absolute value of sufficiency\n",
    "            s += abs(item.get('suff'))\n",
    "            m += 1\n",
    "\n",
    "    # average out the results\n",
    "    avg_comp = c/n if n != 0 else None\n",
    "    avg_suff = s/m if m != 0 else None\n",
    "    avg_length = l / m\n",
    "\n",
    "    results = { \"explainer\" : d[0]['explainer'],\n",
    "                \"original samples\" : len(d),\n",
    "                \"average comp %\" : avg_comp,\n",
    "                \"average suff\" : avg_suff,\n",
    "                \"samples for avg comp\" : n,\n",
    "                \"samples for avg suff\" : m,\n",
    "                \"avg expl length\": avg_length}\n",
    "    \n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 409
  },
  {
   "cell_type": "code",
   "id": "1d4cc16ded7064dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:47:34.974535Z",
     "start_time": "2024-06-01T13:47:34.953566Z"
    }
   },
   "source": [
    "# print(c_and_s[0])\n",
    "\n",
    "avgs = []\n",
    "for c in c_and_s:\n",
    "    a = avg_comp_and_suff(c)\n",
    "    avgs.append(a)\n",
    "\n",
    "pd.DataFrame(avgs)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  explainer  original samples  average comp %  average suff  \\\n",
       "0        IG               100        0.882992      0.045042   \n",
       "1   GradCAM               100        0.624151      0.041177   \n",
       "2    Random               100        0.990827      0.002129   \n",
       "\n",
       "   samples for avg comp  samples for avg suff  avg expl length  \n",
       "0                    83                    85         0.505371  \n",
       "1                    82                    90         0.574239  \n",
       "2                   100                   100         0.999444  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explainer</th>\n",
       "      <th>original samples</th>\n",
       "      <th>average comp %</th>\n",
       "      <th>average suff</th>\n",
       "      <th>samples for avg comp</th>\n",
       "      <th>samples for avg suff</th>\n",
       "      <th>avg expl length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IG</td>\n",
       "      <td>100</td>\n",
       "      <td>0.882992</td>\n",
       "      <td>0.045042</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>0.505371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>100</td>\n",
       "      <td>0.624151</td>\n",
       "      <td>0.041177</td>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>0.574239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random</td>\n",
       "      <td>100</td>\n",
       "      <td>0.990827</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 410
  },
  {
   "cell_type": "code",
   "id": "46d36fa352e12f56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T16:25:23.735999Z",
     "start_time": "2024-06-01T16:25:23.357980Z"
    }
   },
   "source": [
    "# print(dataset.get_smiles_list().index())\n",
    "# print(df.loc[df == 'CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]'])\n",
    "c = comp_and_suff(0)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to cuda\n"
     ]
    }
   ],
   "execution_count": 478
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T11:19:00.766974Z",
     "start_time": "2024-06-02T11:19:00.534565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = convert_real_idx_to_test_idx(509)\n",
    "d = comp_and_suff(i, from_all_data=False)\n",
    "d = comp_and_suff(509, from_all_data=True)\n"
   ],
   "id": "4feffe6724a6e690",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to cuda\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[502], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m i \u001B[38;5;241m=\u001B[39m convert_real_idx_to_test_idx(\u001B[38;5;241m509\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m d \u001B[38;5;241m=\u001B[39m \u001B[43mcomp_and_suff\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_all_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# d = comp_and_suff(509, from_all_data=True)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[496], line 5\u001B[0m, in \u001B[0;36mcomp_and_suff\u001B[1;34m(idx, explainer, from_all_data, modified_formula)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calculates comprehensiveness and sufficiency for a molecule with index idx, given explanation e, returns an object with mol_idx, all the smiles (cleaned and uncleaned), predictions for everything, comprehensiveness and sufficiency, and proportion of explanation vs original molecule. from_all_data True if fetching smile from the whole set, False if from test set.\"\"\"\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# TODO move this out so no need to get the same model every time\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mexplainer_experiment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel_path\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mEXPERIMENT_MODEL\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39meval() \u001B[38;5;66;03m# set model to evaluation mode\u001B[39;00m\n\u001B[0;32m      8\u001B[0m smile, explaining_smile, non_explaining_smile, exp_length \u001B[38;5;241m=\u001B[39m split_molecule(idx, explainer, convert_idx\u001B[38;5;241m=\u001B[39mfrom_all_data)\n",
      "File \u001B[1;32mC:\\git\\rp-repo\\hpajari-Explainable-graph-models-for-biological-and-chemi\\MolRep\\Explainer\\explainerExperiments.py:137\u001B[0m, in \u001B[0;36mExplainerExperiments.get_model\u001B[1;34m(self, dataset, other)\u001B[0m\n\u001B[0;32m    133\u001B[0m model \u001B[38;5;241m=\u001B[39m model_class(dim_features\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mdim_features, dim_target\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mdim_target,\n\u001B[0;32m    134\u001B[0m                     model_configs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_config, dataset_configs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_config)\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_path\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m other\u001B[38;5;241m.\u001B[39mkeys()\n\u001B[1;32m--> 137\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mother\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel_path\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32mC:\\git\\rp-repo\\hpajari-Explainable-graph-models-for-biological-and-chemi\\MolRep\\Utils\\utils.py:213\u001B[0m, in \u001B[0;36mload_checkpoint\u001B[1;34m(path, model, current_args, cuda, logger)\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[0;32m    212\u001B[0m     debug(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMoving model to cuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 213\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32mc:\\git\\rp\\explainable-graph-models-for-biological-and-chemi-main\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:915\u001B[0m, in \u001B[0;36mModule.cuda\u001B[1;34m(self, device)\u001B[0m\n\u001B[0;32m    898\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcuda\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, device: Optional[Union[\u001B[38;5;28mint\u001B[39m, device]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m    899\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001B[39;00m\n\u001B[0;32m    900\u001B[0m \n\u001B[0;32m    901\u001B[0m \u001B[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;124;03m        Module: self\u001B[39;00m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 915\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\git\\rp\\explainable-graph-models-for-biological-and-chemi-main\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\git\\rp\\explainable-graph-models-for-biological-and-chemi-main\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\git\\rp\\explainable-graph-models-for-biological-and-chemi-main\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mc:\\git\\rp\\explainable-graph-models-for-biological-and-chemi-main\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:804\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    801\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    803\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 804\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    805\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    807\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[1;32mc:\\git\\rp\\explainable-graph-models-for-biological-and-chemi-main\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:915\u001B[0m, in \u001B[0;36mModule.cuda.<locals>.<lambda>\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    898\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcuda\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, device: Optional[Union[\u001B[38;5;28mint\u001B[39m, device]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m    899\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001B[39;00m\n\u001B[0;32m    900\u001B[0m \n\u001B[0;32m    901\u001B[0m \u001B[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;124;03m        Module: self\u001B[39;00m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 915\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply(\u001B[38;5;28;01mlambda\u001B[39;00m t: \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU "
     ]
    }
   ],
   "execution_count": 502
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T16:25:25.222992Z",
     "start_time": "2024-06-01T16:25:25.208035Z"
    }
   },
   "cell_type": "code",
   "source": "pd.DataFrame([c, d])",
   "id": "773ae384dee349e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  explainer  mol_idx                                   smile  \\\n",
       "0        IG        3  CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]   \n",
       "1        IG      509  C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F   \n",
       "\n",
       "                   explaining_smile                 clean_explanation  \\\n",
       "0  O=CNc1ccc([N+](=O)[O-])c2ccccc12  O=CNc1ccc([N+](=O)[O-])c2ccccc12   \n",
       "1                     NC=O.c1ccccc1                     NC=O.c1ccccc1   \n",
       "\n",
       "      non_explaining_smile clean_nonexplanation  mol_pred    e_pred   ne_pred  \\\n",
       "0                    CC.CN                CC.CN  0.565568  0.572062  0.922270   \n",
       "1  CCN(C)Cc.C[C@@H]1CC1.cF          C[C@@H]1CC1  0.509846  0.535968  0.438039   \n",
       "\n",
       "       comp      suff  expl length  \n",
       "0 -0.356702 -0.006494     0.888889  \n",
       "1  0.071808 -0.026122     0.500000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explainer</th>\n",
       "      <th>mol_idx</th>\n",
       "      <th>smile</th>\n",
       "      <th>explaining_smile</th>\n",
       "      <th>clean_explanation</th>\n",
       "      <th>non_explaining_smile</th>\n",
       "      <th>clean_nonexplanation</th>\n",
       "      <th>mol_pred</th>\n",
       "      <th>e_pred</th>\n",
       "      <th>ne_pred</th>\n",
       "      <th>comp</th>\n",
       "      <th>suff</th>\n",
       "      <th>expl length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IG</td>\n",
       "      <td>3</td>\n",
       "      <td>CC(=O)N(C)c1ccc(c2c1cccc2)[N+](=O)[O-]</td>\n",
       "      <td>O=CNc1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>O=CNc1ccc([N+](=O)[O-])c2ccccc12</td>\n",
       "      <td>CC.CN</td>\n",
       "      <td>CC.CN</td>\n",
       "      <td>0.565568</td>\n",
       "      <td>0.572062</td>\n",
       "      <td>0.922270</td>\n",
       "      <td>-0.356702</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IG</td>\n",
       "      <td>509</td>\n",
       "      <td>C[C@@H]1C[C@H]1NC(=O)N1CCc2cc(ccc2C1)F</td>\n",
       "      <td>NC=O.c1ccccc1</td>\n",
       "      <td>NC=O.c1ccccc1</td>\n",
       "      <td>CCN(C)Cc.C[C@@H]1CC1.cF</td>\n",
       "      <td>C[C@@H]1CC1</td>\n",
       "      <td>0.509846</td>\n",
       "      <td>0.535968</td>\n",
       "      <td>0.438039</td>\n",
       "      <td>0.071808</td>\n",
       "      <td>-0.026122</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 480
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "48b230d9e8f66525"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
