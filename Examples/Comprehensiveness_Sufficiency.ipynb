{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:24:58.354629Z",
     "start_time": "2024-05-31T18:24:58.340643Z"
    }
   },
   "source": [
    "# A notebook to evaluate GNN explainer performance by calculating Comprehensiveness and Sufficiency \n",
    "#     as defined in \"BAGEL: A Benchmark for Assessing Graph Neural Network Explanations\", by Rathee et al. (2022). \n",
    "# \n",
    "#     Model training and explanation generation adapted from the original MolRep code by Tim Stols.\n"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "d717205e-5947-4c39-b14b-320ceebf664b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:24:58.415990Z",
     "start_time": "2024-05-31T18:24:58.402510Z"
    }
   },
   "source": [
    "# Converted by Tim Stols\n",
    "# python Explainer_Experiments.py --model_name CMPNN \\\n",
    "#                                                        --attribution_name GradInput \\\n",
    "#                                                        --data_path ../MolRep/Datasets/Metabolism/admet2.1_rlm_merge.csv \\\n",
    "#                                                        --dataset_name RLM \\\n",
    "#                                                        --smiles_col COMPOUND_SMILES \\\n",
    "#                                                        --target_col CLF_LABEL \\\n",
    "#                                                        --task_type Multi-Classification \\\n",
    "#                                                        --multiclass_num_classes 3 \\\n",
    "#                                                        --output_dir ../Outputs"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "97e7da87e9d3f7b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:24:58.447866Z",
     "start_time": "2024-05-31T18:24:58.425924Z"
    }
   },
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "LOADING_FROM_FILES = True # True if loading in data from pre-existing files\n",
    "\n",
    "# output directory for trained model and explanations\n",
    "OUTPUT_DIR = f'../Outputs/Experiment'\n",
    "# OUTPUT_DIR = '../Outputs' # original output path, overwrites results\n",
    "\n",
    "# output the explanations (optionally model) here\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "DATASET = 'Benzene'\n",
    "# DATASET = '3MR'\n",
    "\n",
    "# GNN\n",
    "MODEL = 'CMPNN' # Options:  ['MPNN', 'DMPNN', 'CMPNN', 'GIN', 'ECC', 'GAT', 'DGCNN', 'DiffPool', 'GraphSAGE', 'GraphNet']\n",
    "\n",
    "# use specified model, else train a new one\n",
    "# MODELPATH = None\n",
    "MODELPATH = '../Outputs/Experiment/CMPNN_Benzene_explainer/CMPNN_1_epoch.pt' # using this model because it has non-zero F1 score\n",
    "# MODELPATH = '../Models/CMPNN_3MR_explainer_20240519_143138.pt'\n",
    "\n",
    "if MODELPATH is None:\n",
    "    MODELPATH = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", f\"{MODEL}.pt\")\n",
    "\n",
    "# explainers used on the trained model, overwritten down below for testing purposes\n",
    "ATTRIBUTIONS = ['IG', 'Random'] # Options: IG CAM MCTS GradInput GradCAM RandomBaseline # this says RandomBaseLine but code expects 'Random'\n",
    "\n",
    "DATAPATH = '../Datasets/XAI/Benzene/benzene_smiles.csv'\n",
    "# DATAPATH = '../DataSets/3MR/toy_label_mw350.csv'\n",
    "SMILESCOL = 'SMILES'\n",
    "TARGETCOL = 'label'\n",
    "# TARGETCOL = 'label_full' # for 3MR, on my machine the functions targets the wrong label, even if the offending column is deleted\n",
    "\n",
    "ATTRIBUTIONPATH = '../Datasets/XAI/Benzene/attributions.npz'\n",
    "# ATTRIBUTIONPATH = '../DataSets/3MR/attributions.npz'\n",
    "\n",
    "\n",
    "TASKTYPE = 'Classification' # Can be 'Multi-Classification', 'Classification', 'Regression'\n",
    "MULTICLASS_NUM_CLASSES = 2 # Can be 3\n",
    "TESTING = True\n",
    "SPLITTYPE = 'defined' # Can be 'random', 'scaffold', or other defined for dataset\n"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "dfacd7f1cf8943f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:24:58.463824Z",
     "start_time": "2024-05-31T18:24:58.449859Z"
    }
   },
   "source": [
    "import rdkit.Chem\n",
    "from MolRep.Utils.logger import Logger\n",
    "from MolRep.Explainer.explainerExperiments import ExplainerExperiments\n",
    "from MolRep.Explainer.explainerDataWrapper import ExplainerDatasetWrapper\n",
    "from MolRep.Utils.config_from_dict import Grid, Config, DatasetConfig\n",
    "from pathlib import Path\n",
    "import os\n",
    "# from numba.cuda import args\n",
    "\n",
    "# torch.set_num_threads(1)\n",
    "\n",
    "# set up the model\n",
    "data_stats = {\n",
    "            'name': DATASET,\n",
    "            'path': DATAPATH,\n",
    "            'smiles_column': SMILESCOL,\n",
    "            'target_columns': [TARGETCOL],\n",
    "            'attribution_path': ATTRIBUTIONPATH,\n",
    "            'task_type': TASKTYPE,\n",
    "            'multiclass_num_classes': MULTICLASS_NUM_CLASSES,\n",
    "            'metric_type': 'rmse' if TASKTYPE == 'Regression' else ['acc', 'auc', 'f1', 'precision', 'recall'],\n",
    "            'split_type': SPLITTYPE\n",
    "}\n",
    "\n",
    "if TESTING:\n",
    "    data_stats['additional_info'] = {\"splits\":'SPLIT'}\n",
    "    \n",
    "# output for vector groups\n",
    "data_dir = Path('../MolRep/Data')\n",
    "split_dir = Path('../MolRep/Splits')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(split_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "b4e5f3f497340e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:24:58.511731Z",
     "start_time": "2024-05-31T18:24:58.465817Z"
    }
   },
   "source": [
    "config_file = '../MolRep/Configs/config_{}.yml'.format(MODEL)\n",
    "model_configurations = Grid(config_file)\n",
    "model_configuration = Config(**model_configurations[0])\n",
    "dataset_configuration = DatasetConfig(DATASET, data_dict=data_stats)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMPNN\n",
      "{'GIN': <class 'MolRep.Models.graph_based.GIN.GIN'>, 'ECC': <class 'MolRep.Models.graph_based.ECC.ECC'>, 'DGCNN': <class 'MolRep.Models.graph_based.DGCNN.DGCNN'>, 'DiffPool': <class 'MolRep.Models.graph_based.DiffPool.DiffPool'>, 'GraphSAGE': <class 'MolRep.Models.graph_based.GraphSAGE.GraphSAGE'>, 'GAT': <class 'MolRep.Models.graph_based.GAT.GAT'>, 'GraphNet': <class 'MolRep.Models.graph_based.GraphNet.GraphNet'>, 'MPNN': <class 'MolRep.Models.graph_based.MPNN.MPNN'>, 'CMPNN': <class 'MolRep.Models.graph_based.CMPNN.CMPNN'>, 'DMPNN': <class 'MolRep.Models.graph_based.DMPNN.DMPNN'>, 'MAT': <class 'MolRep.Models.sequence_based.MAT.MAT'>, 'CoMPT': <class 'MolRep.Models.sequence_based.CoMPT.CoMPT'>, 'BiLSTM': <class 'MolRep.Models.sequence_based.BiLSTM.BiLSTM'>, 'SALSTM': <class 'MolRep.Models.sequence_based.SALSTM.SALSTM'>, 'Transformer': <class 'MolRep.Models.sequence_based.Transformer.Transformer'>, 'VAE': <class 'MolRep.Models.unsupervised_based.VAE.VAE'>, 'RandomForest': <class 'MolRep.Models.unsupervised_based.RandomForest.RandomForest'>, 'XGboost': <class 'MolRep.Models.unsupervised_based.XGboost.XGboost'>, 'PLNLP': <class 'MolRep.Interactions.link_models.PLNLP.PLNLP.PLNLP'>, 'CFLP': <class 'MolRep.Interactions.link_models.CFLP.CFLP.CFLP'>}\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "6f5aafb16b07d4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:25:02.174254Z",
     "start_time": "2024-05-31T18:24:58.513693Z"
    }
   },
   "source": [
    "# export path: model + dataset name\n",
    "exp_path = os.path.join(output_dir, f'{model_configuration.exp_name}_{dataset_configuration.exp_name}_explainer')\n",
    "\n",
    "# dataset_config: configuration of the model\n",
    "# model_name: name of the model\n",
    "# split_dir: path to defined splits of the dataset\n",
    "# features_dir: path to data directory\n",
    "dataset = ExplainerDatasetWrapper(dataset_config=dataset_configuration,\n",
    "                                  model_name=model_configuration.exp_name,\n",
    "                                  split_dir=split_dir, features_dir=data_dir)\n",
    "\n",
    "# set up the experiment\n",
    "explainer_experiment = ExplainerExperiments(model_configuration, dataset_configuration, exp_path)"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "72368846a986d178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:25:02.331652Z",
     "start_time": "2024-05-31T18:25:02.175220Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# import torch\n",
    "\n",
    "# to load a model from a file without having used it, need to instantiate it first\n",
    "# model = CMPNN(model_configuration)\n",
    "# state_dict = torch.load(MODELPATH)\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "# Options: IG CAM MCTS GradInput GradCAM RandomBaseline # says RandomBaseLine but code expects 'Random'\n",
    "ATTRIBUTIONS = []\n",
    "\n",
    "atom_importances = []\n",
    "explainer_accuracies = []\n",
    "\n",
    "if LOADING_FROM_FILES :\n",
    "    LOGGER_BASE = os.path.join(OUTPUT_DIR, \"Logger\", f\"{DATASET}_explainer\")\n",
    "    logger = Logger(str(os.path.join(LOGGER_BASE, f\"{MODEL}_{DATASET}_explainer_by_experiment.log\")), mode='a')\n",
    "    \n",
    "    ### TODO on first run, uncomment, on subsequent runs can leave commented out ###\n",
    "    # _, _, _ = explainer_experiment.molecule_importance(dataset=dataset, attribution=ATTRIBUTIONS[0], logger=logger, other={'model_path':MODELPATH}, testing=TESTING)\n",
    "    \n",
    "    # read in used explainers\n",
    "    explainer_accs_path = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\" , f\"explainer_accuracies.csv\")\n",
    "    explainer_accuracies_df = pd.read_csv(explainer_accs_path) # used for looking at, nothing else\n",
    "    \n",
    "    for e in explainer_accuracies_df['explainer']:\n",
    "        ATTRIBUTIONS.append(e)\n",
    " \n",
    "    explainer_importances = []\n",
    "    \n",
    "    # get atom importances per explainer\n",
    "    for ATTRIBUTION in ATTRIBUTIONS:\n",
    "        atom_imp_for_expl = []\n",
    "        \n",
    "        imp_path = os.path.join(output_dir, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}_{model_configuration['num_epochs']}_epochs\" , \"importances.csv\")\n",
    "\n",
    "        # atom importances are given as a string of an array of floats \n",
    "        importance = pd.read_csv(imp_path)['Atom_importance']\n",
    "        \n",
    "        for _, row in importance.items():\n",
    "            # remove brackets and newlines\n",
    "            clean_imp = re.sub(r'[\\[\\]\\n]', '', row).strip()\n",
    "            \n",
    "            # split by whitespace and convert to float\n",
    "            float_imps = [float(x) for x in clean_imp.split()]\n",
    "            atom_imp_for_expl.append(float_imps)\n",
    "\n",
    "        atom_importances.append(atom_imp_for_expl)    \n",
    "    \n",
    "else: \n",
    "    ATTRIBUTIONS = ['IG', 'GradCAM', 'Random']\n",
    "    # generate explanations for each explainer\n",
    "    for ATTRIBUTION in ATTRIBUTIONS:\n",
    "        LOGGER_BASE = os.path.join(OUTPUT_DIR, \"Logger\", f\"{DATASET}_explainer\")\n",
    "        logger = Logger(str(os.path.join(LOGGER_BASE, f\"{MODEL}_{DATASET}_explainer_by_{ATTRIBUTION}.log\")), mode='a')\n",
    "        \n",
    "        # define path for graphics\n",
    "        svg_dir = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}_{model_configuration['num_epochs']}_epochs\")\n",
    "        os.makedirs(svg_dir, exist_ok=True)\n",
    "    \n",
    "        ### comment out if a model exists and want to use it with all models, else trains a new one for each ###\n",
    "        # explainer_experiment.run_valid(dataset, ATTRIBUTION, logger=logger, other={'model_path':MODELPATH})\n",
    "    \n",
    "        ## if model doesn't exist, train a new one\n",
    "        # if not os.path.exists(MODELPATH):\n",
    "        #     explainer_experiment.run_valid(dataset, ATTRIBUTION, logger=logger, other={'model_path':MODELPATH})\n",
    "        \n",
    "        # generate attributions; bond_importance is None in all the tests I ran\n",
    "        results, atom_importance, bond_importance = explainer_experiment.molecule_importance(dataset=dataset, attribution=ATTRIBUTION, logger=logger, other={'model_path':MODELPATH}, testing=TESTING)\n",
    "        \n",
    "        if DATASET in ['hERG', 'CYP3A4']:\n",
    "            attribution_results, opt_threshold = explainer_experiment.evaluate_cliffs(dataset, atom_importance, bond_importance)\n",
    "        else:\n",
    "            binary = True if ATTRIBUTION == 'MCTS' else False\n",
    "            #TODO \"not working, because ATTRIBUTIONPATH is not set and attributions are not saved\"\n",
    "            attribution_results, opt_threshold = explainer_experiment.evaluate_attributions(dataset, atom_importance, bond_importance, binary=binary)\n",
    "         \n",
    "        # creates visualizations from the datasets and outputs them to svg_dir\n",
    "        explainer_experiment.visualization(dataset, atom_importance, bond_importance, svg_dir=svg_dir, testing=TESTING)\n",
    "    \n",
    "        # write the results, atom importances to a file\n",
    "        df = pd.DataFrame(\n",
    "            {'SMILES': dataset.get_smiles_list(), 'Atom_importance': atom_importance, 'Bond_importance':bond_importance}\n",
    "        )\n",
    "        df.to_csv(os.path.join(svg_dir, \"importances.csv\"), index=False)\n",
    "    \n",
    "        # create an object from the pre-established metrics, add to list (include model results to ensure they're all the same)\n",
    "        acc = {\"explainer\" : ATTRIBUTION,\n",
    "               \"model\" : MODEL,\n",
    "                \"epochs\" : model_configuration['num_epochs'],\n",
    "                \"acc\" : results['acc'],\n",
    "                \"auc\" : results['auc'], \n",
    "                \"f1\" : results['f1'], \n",
    "                \"precision\" : results['precision'], \n",
    "                \"recall\" : results['recall'], \n",
    "                \"Attribution AUROC\" : attribution_results['Attribution AUROC'], \n",
    "                \"Attribution F1\" : attribution_results['Attribution F1'], \n",
    "                \"Attribution ACC\" : attribution_results['Attribution ACC'], \n",
    "                \"Attribution Precision\" : attribution_results['Attribution Precision'], \n",
    "                \"Attribution AUROC Mean\" : attribution_results['Attribution AUROC Mean'], \n",
    "                \"Attribution ACC Mean\" : attribution_results['Attribution ACC Mean'] }\n",
    "        explainer_accuracies.append(acc)\n",
    "    \n",
    "        # add atom importances to a list, fetch them by index of attributions on the list used\n",
    "        # importance = {\"Atom_importance\" : atom_importance}\n",
    "        atom_importances.append(atom_importance)\n",
    "       \n",
    "    # TODO store these in a file\n",
    "    explainer_accuracies_df = pd.DataFrame(explainer_accuracies)\n",
    "    \n",
    "    # dataframe for storing atom importances per explainer in a file later\n",
    "    importances_df = pd.DataFrame(atom_importances)"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "26dc4c46c4a7d504",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-05-31T18:25:02.362607Z",
     "start_time": "2024-05-31T18:25:02.332650Z"
    }
   },
   "source": [
    "import copy\n",
    "\n",
    "# path to model and explanations\n",
    "\n",
    "x = os.path.join(output_dir, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"IG_{model_configuration['num_epochs']}_epochs\" , \"importances.csv\")\n",
    "# IMPORTANCES_PATH = '../Outputs/20240524_164403/CMPNN_Benzene_explainer/SVG/IG_1_epochs/importances.csv' \n",
    "\n",
    "# os.path.join(output_dir, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}_{DATASET}_explainer\" , \"importances.csv\")\n",
    "IMPORTANCES_PATH = x\n",
    "\n",
    "\n",
    "# svg_dir = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}_{model_configuration['num_epochs']}_epochs\")\n",
    "# df.to_csv(os.path.join(svg_dir, ), index=False)\n",
    "\n",
    "# df = pd.read_csv(IMPORTANCES_PATH)\n",
    "# print(df['Atom_importance'].iat[3])\n",
    "\n",
    "# TODO if reading importances from a csv, must convert importances from a string of an array of floats to an actual array of floats\n",
    "# TODO write explainer_accuracies and atom importances to a file if they arent already\n",
    "# TODO write a method to import them back to notebook\n",
    "\n",
    "# y = os.path.join(output_dir, f\"{MODEL}_{DATASET}_explainer\", f\"{model_configuration['num_epochs']}_epochs\")\n",
    "# os.makedirs(y, exist_ok=True)\n",
    "\n",
    "# df.to_csv(os.path.join(svg_dir, \"importances.csv\"), index=False)\n",
    "\n",
    "# explainer_accuracies_df.to_csv(y, \"explainer_accuracies.csv\", index=False)\n",
    "explainer_accuracies_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  explainer  model  epochs     acc      auc        f1  precision    recall  \\\n",
       "0        IG  CMPNN       1  0.7475  0.84503  0.772693   0.707904  0.850537   \n",
       "1   GradCAM  CMPNN       1  0.7475  0.84503  0.772693   0.707904  0.850537   \n",
       "2    Random  CMPNN       1  0.7475  0.84503  0.772693   0.707904  0.850537   \n",
       "\n",
       "   Attribution AUROC  Attribution F1  Attribution ACC  Attribution Precision  \\\n",
       "0           0.948686        0.271034         0.826074               0.417503   \n",
       "1           0.946286        0.231217         0.815562               0.386618   \n",
       "2           0.495094        0.008616         0.809156               0.037847   \n",
       "\n",
       "   Attribution AUROC Mean  Attribution ACC Mean  \n",
       "0                0.901842              0.822130  \n",
       "1                0.893762              0.811085  \n",
       "2                0.497988              0.798624  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explainer</th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Attribution AUROC</th>\n",
       "      <th>Attribution F1</th>\n",
       "      <th>Attribution ACC</th>\n",
       "      <th>Attribution Precision</th>\n",
       "      <th>Attribution AUROC Mean</th>\n",
       "      <th>Attribution ACC Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IG</td>\n",
       "      <td>CMPNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.84503</td>\n",
       "      <td>0.772693</td>\n",
       "      <td>0.707904</td>\n",
       "      <td>0.850537</td>\n",
       "      <td>0.948686</td>\n",
       "      <td>0.271034</td>\n",
       "      <td>0.826074</td>\n",
       "      <td>0.417503</td>\n",
       "      <td>0.901842</td>\n",
       "      <td>0.822130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradCAM</td>\n",
       "      <td>CMPNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.84503</td>\n",
       "      <td>0.772693</td>\n",
       "      <td>0.707904</td>\n",
       "      <td>0.850537</td>\n",
       "      <td>0.946286</td>\n",
       "      <td>0.231217</td>\n",
       "      <td>0.815562</td>\n",
       "      <td>0.386618</td>\n",
       "      <td>0.893762</td>\n",
       "      <td>0.811085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random</td>\n",
       "      <td>CMPNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.84503</td>\n",
       "      <td>0.772693</td>\n",
       "      <td>0.707904</td>\n",
       "      <td>0.850537</td>\n",
       "      <td>0.495094</td>\n",
       "      <td>0.008616</td>\n",
       "      <td>0.809156</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>0.497988</td>\n",
       "      <td>0.798624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "86a613fd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-31T18:25:02.379528Z",
     "start_time": "2024-05-31T18:25:02.364565Z"
    }
   },
   "source": "\n",
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "9319bd0830aedaf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:41:50.072917Z",
     "start_time": "2024-05-31T18:41:50.054966Z"
    }
   },
   "source": [
    "def split_molecule(mol_idx:int, attr='IG', threshold=1e-4, convert_idx=False):\n",
    "    \"\"\"Splits the given molecule into explaining and non-explaining SMILES based on given explanation, returns those and the SMILES of the molecule. Threshold value is the same as in explainerExperiments.py visualization(). Convert idx True if fetching smile from the entire dataset, False if looking by index in test set\"\"\"\n",
    "    \n",
    "    if convert_idx:\n",
    "        smile = dataset.whole_data_df.SMILES.iat[mol_idx]\n",
    "    else:\n",
    "        # testing = True by default\n",
    "        smile = dataset.get_smiles_list(testing=True)[mol_idx]\n",
    "    \n",
    "    # atom importances depend on what explainer method is used, mol_idx is convenient\n",
    "    expl_idx = ATTRIBUTIONS.index(attr)\n",
    "    a_importances = atom_importances[expl_idx][mol_idx]\n",
    "    \n",
    "    # print(type(a_importances), a_importances, type(a_importances[0]))\n",
    "    # print(\"threshold\", threshold, type(threshold))\n",
    "\n",
    "    original_mol = rdkit.Chem.RWMol(rdkit.Chem.MolFromSmiles(smile))\n",
    "     \n",
    "    non_explaining_atom_idxs = []\n",
    "    explaining_atom_idxs = []\n",
    "    for idx in range(len(original_mol.GetAtoms())):\n",
    "        if a_importances[idx] < threshold:\n",
    "            non_explaining_atom_idxs.append(idx)\n",
    "        else:\n",
    "            explaining_atom_idxs.append(idx)\n",
    "            \n",
    "    # reverse because removing atoms causes indices of others to shift\n",
    "    non_explaining_atom_idxs.reverse()\n",
    "    explaining_atom_idxs.reverse()\n",
    "    \n",
    "    # number of atoms in explanation vs whole molecule \n",
    "    exp_length = len(explaining_atom_idxs) / ( len(explaining_atom_idxs) + len(non_explaining_atom_idxs))\n",
    "    \n",
    "    # find (non)explaining bonds where at least one end is a non-explaining atom\n",
    "    non_explaining_bonds = []\n",
    "    explaining_bonds = []\n",
    "    \n",
    "    for bond in original_mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        \n",
    "        # if both end and start in explaining atoms, the edge is explaining \n",
    "        if (i and j) not in non_explaining_atom_idxs :\n",
    "            explaining_bonds.append((i, j))\n",
    "            explaining_bonds.append((j, i))\n",
    "        else:\n",
    "            non_explaining_bonds.append((i, j))\n",
    "            non_explaining_bonds.append((j, i))\n",
    "            \n",
    "            # remove i or j from explaining atoms \n",
    "            # so bonds between explaining and nonexplaining atoms are kept in non-explaining molecules\n",
    "            if i in explaining_atom_idxs: explaining_atom_idxs.remove(i)\n",
    "            if j in explaining_atom_idxs: explaining_atom_idxs.remove(j)\n",
    "    \n",
    "    # explaining molecule has non-explaining bonds and atoms removed\n",
    "    explaining_mol = copy.deepcopy(original_mol)\n",
    "    for (i, j) in non_explaining_bonds:\n",
    "        explaining_mol.RemoveBond(i, j)\n",
    "    \n",
    "    for idx in non_explaining_atom_idxs:\n",
    "        explaining_mol.RemoveAtom(idx)\n",
    "\n",
    "    explaining_smile = rdkit.Chem.MolToSmiles(explaining_mol)\n",
    "    \n",
    "    # comprehensiveness uses non-explaining atoms and edges\n",
    "    non_explaining_mol = copy.deepcopy(original_mol)\n",
    "    \n",
    "    for (i, j) in explaining_bonds:\n",
    "        non_explaining_mol.RemoveBond(i, j)\n",
    "\n",
    "    # remove explaining atoms    \n",
    "    for i in explaining_atom_idxs:\n",
    "        non_explaining_mol.RemoveAtom(i)\n",
    "    \n",
    "    non_explaining_smile = rdkit.Chem.MolToSmiles(non_explaining_mol)\n",
    "    \n",
    "    return smile, explaining_smile, non_explaining_smile, exp_length"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "id": "d2aaed81-856d-436e-b709-e74873673a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:28:13.519635Z",
     "start_time": "2024-05-31T18:28:13.508631Z"
    }
   },
   "source": [
    "s, e, n, m = split_molecule(137, convert_idx=True)\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# print(s)\n",
    "# print(e)\n",
    "# print(n)\n",
    "# Draw.MolToImage(Chem.MolFromSmiles(s))\n",
    "# Draw.MolToImage(Chem.MolFromSmiles(e))\n",
    "# Draw.MolToImage(Chem.MolFromSmiles(n))\n",
    "# print(ATTRIBUTION)"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "id": "bd22e2c2-02cb-4660-be4f-2d556d4042e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:07:52.065254Z",
     "start_time": "2024-05-31T18:07:52.052287Z"
    }
   },
   "source": [
    "\n",
    "# Draw.MolToImage(Chem.MolFromSmiles(n))\n",
    "# 17 => 93.png"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "ebf3d2ee8dfcd116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:07:52.080260Z",
     "start_time": "2024-05-31T18:07:52.068244Z"
    }
   },
   "source": [
    "import torch\n",
    "from MolRep.Featurization.MPNN_embeddings import MolGraph, BatchMolGraph\n",
    "from rdkit.Chem import MolFromSmiles, rdmolops\n",
    "\n",
    "def tensors_to_device(smile, batch):\n",
    "    \"\"\"Sets nodes, edges, a2b, b2a and adjacency matrix tensors of a molecule to the device\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    adj = rdmolops.GetAdjacencyMatrix(MolFromSmiles(smile))\n",
    "    \n",
    "    features = {\n",
    "        'nodes' : batch.f_atoms, \n",
    "        'edges' : batch.f_bonds,\n",
    "        'a2b' : batch.a2b,\n",
    "        'b2a' : batch.b2a,\n",
    "        'adjacency' : torch.FloatTensor(adj) \n",
    "    }\n",
    "    \n",
    "    for i in features:\n",
    "        features[i].to(device)\n",
    "        \n",
    "    return features['nodes'], features['edges'], features['a2b'], features['b2a'], features['adjacency']"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "e2d35283cb961a64",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-31T18:55:04.921746Z",
     "start_time": "2024-05-31T18:55:04.911771Z"
    }
   },
   "source": [
    "import re\n",
    "def clean_smile(smile:str) -> str:\n",
    "    \"\"\"Takes a (fragmented) SMILES as input and returns concatenated valid fragments of it. Does nothing if input is already valid.\n",
    "    e.g: C.CC.F.O.n.n -> C.CC.F.O\n",
    "    \"\"\"\n",
    "    cs = \"\"\n",
    "    # 1. split n/explanations into a list\n",
    "    subm = smile.split('.')\n",
    "    \n",
    "    # 2. try to convert the pieces into a molgraph\n",
    "    # if success, append to a new string cs (cut string)\n",
    "    for (i, sm) in enumerate(subm): \n",
    "        try:\n",
    "            MolGraph(sm)\n",
    "            cs += sm\n",
    "            if i < len(subm) - 1:\n",
    "                cs += '.'\n",
    "        except:\n",
    "            if i < len(subm) - 1:\n",
    "                cs += '.'\n",
    "            continue\n",
    "        \n",
    "    # remove repetitions and the first and last period from the string\n",
    "    cs = re.sub(\"\\.+\", \".\", cs)\n",
    "    # ReGeX from https://stackoverflow.com/a/3331982\n",
    "    cs = re.sub(\"\\.([^.]*)$\", \"\", cs)\n",
    "    cs = re.sub(\"(^\\.)\", \"\", cs)\n",
    "    return cs\n"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "id": "790fcae9ee2dbea1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:07:52.110136Z",
     "start_time": "2024-05-31T18:07:52.097167Z"
    }
   },
   "source": [
    "def clear_gpu_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "EXPERIMENT_MODEL = MODELPATH"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "4d6c91327aefcf6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:46:42.337028Z",
     "start_time": "2024-05-31T18:46:42.312020Z"
    }
   },
   "source": [
    "def convert_from_test_to_real_idx(idx):\n",
    "    \"\"\"Converts the index used in the test set to the index in the whole dataset.\"\"\"    \n",
    "    smile = dataset.get_smiles_list(testing=True)[idx]\n",
    "    \n",
    "    data = dataset.whole_data_df \n",
    "    return data.loc[(data == smile).any(axis=1)].index[0]\n",
    "\n",
    "\n",
    "def comp_and_suff(idx, explainer = 'IG', convert_idx=False) :\n",
    "    \"\"\"Calculates comprehensiveness and sufficiency for a molecule with index idx, given explanation e, returns an object with mol_idx, all the smiles (cleaned and uncleaned), predictions for everything, comprehensiveness and sufficiency, and proportion of explanation vs original molecule. Convert_idx True if fetching smile from the whole set, False if test set.\"\"\"\n",
    "    \n",
    "    # TODO move this out so no need to get the same model every time\n",
    "    model = explainer_experiment.get_model(dataset, other={'model_path':EXPERIMENT_MODEL})\n",
    "    model.eval() # set model to evaluation mode\n",
    "\n",
    "    smile, explaining_smile, non_explaining_smile, exp_length = split_molecule(idx, explainer, convert_idx=convert_idx)\n",
    "    \n",
    "    # clean up the smiles, split may have created invalid molecules\n",
    "    clean_smiles = list(map(clean_smile, [smile, explaining_smile, non_explaining_smile]))\n",
    "\n",
    "    preds = []\n",
    "    for (i, cs) in enumerate(clean_smiles):\n",
    "        if cs == \"\": # don't predict empty strings\n",
    "            # if no non-explaining, then comp is f(g) = great, because the whole molecule explains the prediction!\n",
    "            # if no explaining, suff is f(g) = maybe good?, because there's nothing to explain why prediction was made?\n",
    "            \n",
    "            # none to predict to begin with != none being valid\n",
    "            if cs == [smile, explaining_smile, non_explaining_smile][i]:\n",
    "                preds.append([0]) # no (non)explaining to begin with is a-okay     \n",
    "            else:\n",
    "                preds.append([None]) # no valid strings after cleaning up less so\n",
    "            continue\n",
    "            \n",
    "        subpreds = []\n",
    "\n",
    "        splits = cs.split('.')\n",
    "        for split in splits:\n",
    "        \n",
    "            # 3. convert s to molgraph\n",
    "            try :\n",
    "                mol = MolGraph(split)\n",
    "                g_input = BatchMolGraph( [mol])\n",
    "                atoms, bonds, a2b, b2a, adjacency = tensors_to_device(cs, g_input)\n",
    "        \n",
    "                with torch.no_grad():\n",
    "                    # TODO investigate None params?\n",
    "                    #   Args for mol2graph:\n",
    "                    # - mols: A list of SMILES or a list of RDKit molecules.\n",
    "                    # - atom_descriptors_batch: A list of 2D numpy array containing additional atom descriptors to featurize the molecule\n",
    "                    subpred = model([[split], None, None]).item()\n",
    "        \n",
    "                subpreds.append(subpred)\n",
    "            except:\n",
    "                # If model couldn't predict the subgraph for whatever weird reason\n",
    "                # I don't know why this would happen, but evidently it does happen\n",
    "                subpreds.append(None)\n",
    "        preds.append(subpreds)\n",
    "    \n",
    "    try:\n",
    "        g_pred = preds[0][0] # prediction of original molecule, there is only one so do nothing\n",
    "        e_pred = None if preds[1] == [None] else sum(preds[1]) / len(preds[1]) # prediction of explaining molecules : take the mean\n",
    "        n_pred = None if preds[2] == [None] else sum(preds[2]) # prediction of non-explaining molecules : sum\n",
    "        \n",
    "        # f = model prediction given a smile\n",
    "        # comp = f(smile) - f(non_explaining_smile)\n",
    "        # suff = f (smile) - f(explaining_smile)\n",
    "        \n",
    "        comp = g_pred - n_pred if n_pred is not None else None\n",
    "        suff = g_pred - e_pred if e_pred is not None else None\n",
    "        \n",
    "        result = {\n",
    "            \"mol_idx\": i,\n",
    "            \"smile\" : smile,\n",
    "            \"explaining_smile\" : explaining_smile,\n",
    "            \"clean_explanation\" : clean_smiles[1],\n",
    "            \"non_explaining_smile\" : non_explaining_smile,\n",
    "            \"clean_nonexplanation\": clean_smiles[2],\n",
    "            \"mol_pred\": g_pred,\n",
    "            \"e_pred\": e_pred,\n",
    "            \"ne_pred\": n_pred,\n",
    "            \"comp\" : comp,\n",
    "            \"suff\" : suff,\n",
    "            \"exp length\": exp_length\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    except:\n",
    "        # print \n",
    "        print(preds, \" idx in dataset: \", convert_from_test_to_real_idx(idx) , \" idx in test set: \", idx)\n"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:07:52.141052Z",
     "start_time": "2024-05-31T18:07:52.128085Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fcadf906349f859f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "b5126cce8ec43d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:07:52.156012Z",
     "start_time": "2024-05-31T18:07:52.143051Z"
    }
   },
   "source": [
    "def comp_and_suff_data(dataset, attr):\n",
    "    \"\"\"Calculates and accumulates the comprehensiveness and sufficiency for all molecules within the test set of the provided dataset.\"\"\"\n",
    "    c_and_s = []\n",
    "    \n",
    "    # actually only care about the index, because further down the line we're getting things by index in the test set\n",
    "    for (i, _) in enumerate(dataset.get_smiles_idxs(testing=True)):\n",
    "        torch.cuda.empty_cache() # please be enough to allow things to run smoothly\n",
    "        vals = comp_and_suff(i, attr)\n",
    "        c_and_s.append(vals)\n",
    "    return c_and_s"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "f4d36dd3cdedc7cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:07:52.172Z",
     "start_time": "2024-05-31T18:07:52.158005Z"
    }
   },
   "source": [
    "# TODO 2 further work\n",
    "# save results of comp-suff for transparency\n",
    "# use a different explainer on the model\n",
    "# save those results\n",
    "\n",
    "def comp_and_suff_for_all_explainers(explainers, importances_df):\n",
    "    \"\"\"Calculates comp and suff for all explainers\"\"\"\n",
    "    comps = []\n",
    "    \n",
    "    for (i, explainer) in enumerate(explainers):\n",
    "        torch.cuda.empty_cache() # please be enough to allow things to run smoothly\n",
    "        comp = comp_and_suff_data(importances_df.iloc[i], explainer)\n",
    "        # print(comp)\n",
    "        comps.append(comp)\n",
    "    return comps\n",
    "\n",
    "# c_and_s = comp_and_suff_for_all_explainers(ATTRIBUTIONS, importances_df)\n",
    "# c_and_s = comp_and_suff_data(dataset, 'IG')"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:55:20.708714Z",
     "start_time": "2024-05-31T18:55:20.448592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(\"hi\")\n",
    "#137 breaks\n",
    "clear_gpu_memory()\n",
    "\n",
    "# Cc1ccc(cc1)c1nc(c(nn1)C)Sc1cccc(c1)C(F)(F)F\n",
    "comp_and_suff(137, convert_idx=False) # this breaks in mol split \n",
    "# idx is wrt index in the test set, not \n",
    "\n",
    "s , e, n, _ = split_molecule(137, convert_idx=False)\n",
    "print(s, e, n, convert_from_test_to_real_idx(137))\n",
    "\n",
    "clean_smile(e)\n",
    "# clean_smile(n)"
   ],
   "id": "a4afefaa-2d6e-4c9c-b544-3bee1c8aa60c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to cuda\n",
      "Cc1ccc(cc1)c1nc(c(nn1)C)Sc1cccc(c1)C(F)(F)F c-c1ccccc1.c1ccccc1.cc Cc.Ccnn.cC(F)(F)F.cS.cn 727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c1ccccc1'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "id": "f863193e8bc3725f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:07:53.113001Z",
     "start_time": "2024-05-31T18:07:53.112004Z"
    }
   },
   "source": [
    "def avg_comp_and_suff(d):\n",
    "    \"\"\"Calculates the average comp and suff for a list of data. Returns the original data length, avg comp and suff, and how many samples were used to calculate them.\"\"\"\n",
    "\n",
    "    c, n, s, m = 0, 0, 0, 0\n",
    "    \n",
    "    for i in range(len(d)):\n",
    "        item = d[i]\n",
    "        mol_pred = item.get('mol_pred')\n",
    "        e_pred = item.get('e_pred')\n",
    "        ne_pred = item.get('ne_pred')\n",
    "        \n",
    "        print(i, mol_pred, e_pred, ne_pred)\n",
    "\n",
    "        if ne_pred is not None:\n",
    "            # absolute difference between mol prediction and comprehensiveness \n",
    "            c += (abs(mol_pred - item.get('comp')) )\n",
    "            n += 1\n",
    "        \n",
    "        if e_pred is not None:\n",
    "            # absolute value of e_prediction \n",
    "            s += abs(item.get('suff'))\n",
    "            m += 1\n",
    "        \n",
    "    # average out the results\n",
    "    avg_comp = c/n if n != 0 else None\n",
    "    avg_suff = s/m if m != 0 else None\n",
    "    \n",
    "    results = {\"original samples\" : len(d), \n",
    "               \"average comp\" : avg_comp,\n",
    "               \"average suff\" : avg_suff,\n",
    "               \"samples for avg comp\" : n,\n",
    "               \"samples for avg suff\" : m}\n",
    "    \n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d4cc16ded7064dd",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "773ae384dee349e3",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
