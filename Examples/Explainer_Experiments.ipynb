{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:56:57.298952Z",
     "start_time": "2024-05-23T16:56:57.282991Z"
    }
   },
   "source": [
    "# Converted by Tim Stols\n",
    "# python Explainer_Experiments.py --model_name CMPNN \\\n",
    "#                                                        --attribution_name GradInput \\\n",
    "#                                                        --data_path ../MolRep/Datasets/Metabolism/admet2.1_rlm_merge.csv \\\n",
    "#                                                        --dataset_name RLM \\\n",
    "#                                                        --smiles_col COMPOUND_SMILES \\\n",
    "#                                                        --target_col CLF_LABEL \\\n",
    "#                                                        --task_type Multi-Classification \\\n",
    "#                                                        --multiclass_num_classes 3 \\\n",
    "#                                                        --output_dir ../Outputs"
   ],
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:56:57.329867Z",
     "start_time": "2024-05-23T16:56:57.311915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np"
   ],
   "id": "5d01e66301d55fb2",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:56:57.361784Z",
     "start_time": "2024-05-23T16:56:57.353806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# OUTPUT_DIR = f'../Outputs/{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "# # OUTPUT_DIR = '../Outputs'\n",
    "# DATASET = '3MR'\n",
    "# \n",
    "# # GNN\n",
    "# MODEL = 'GraphNet' # Options:  ['MPNN', 'DMPNN', 'CMPNN', 'GIN', 'ECC', 'GAT', 'DGCNN', 'DiffPool', 'GraphSAGE', 'GraphNet']\n",
    "# \n",
    "# # explainer\n",
    "# ATTRIBUTION = 'IG' # Options: IG CAM MCTS GradInput GradCAM RandomBaseline\n",
    "# \n",
    "# DATAPATH = '../DataSets/3MR/toy_label_mw350.csv'\n",
    "# SMILESCOL = 'SMILES'\n",
    "# TARGETCOL = 'label_full'\n",
    "# \n",
    "# ATTRIBUTIONPATH = '../DataSets/3MR/attributions.npz'\n",
    "# \n",
    "# TASKTYPE = 'Regression' # Can be 'Multi-Classification', 'Classification', 'Regression'\n",
    "# MULTICLASS_NUM_CLASSES = 2 # Can be 3\n",
    "# TESTING = True\n",
    "# SPLITTYPE = 'defined' # Can be 'random', 'scaffold', or other defined for dataset"
   ],
   "id": "21bea3823cc4b142",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:56:57.393211Z",
     "start_time": "2024-05-23T16:56:57.382725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# OUTPUT_DIR = f'../Outputs/{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "# # OUTPUT_DIR = '../Outputs'\n",
    "# DATASET = 'Liver'\n",
    "# \n",
    "# # GNN\n",
    "# MODEL = 'CMPNN' # Options:  ['MPNN', 'DMPNN', 'CMPNN', 'GIN', 'ECC', 'GAT', 'DGCNN', 'DiffPool', 'GraphSAGE', 'GraphNet']\n",
    "# \n",
    "# # explainer\n",
    "# ATTRIBUTION = 'IG' # Options: IG CAM MCTS GradInput GradCAM RandomBaseline\n",
    "# \n",
    "# DATAPATH = '../Datasets/XAI/Liver/liver.csv'\n",
    "# SMILESCOL = 'SMILES'\n",
    "# TARGETCOL = 'label'\n",
    "# \n",
    "# ATTRIBUTIONPATH = '../Datasets/XAI/Liver/attributions.npz'\n",
    "# \n",
    "# TASKTYPE = 'Classification' # Can be 'Multi-Classification', 'Classification', 'Regression'\n",
    "# MULTICLASS_NUM_CLASSES = 2 # Can be 3\n",
    "# TESTING = True\n",
    "# SPLITTYPE = 'defined' # Can be 'random', 'scaffold', or other defined for dataset"
   ],
   "id": "607c8ebd7f318ebd",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T17:04:07.642180Z",
     "start_time": "2024-05-23T17:04:07.633143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "OUTPUT_DIR = f'../Outputs/{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "# OUTPUT_DIR = '../Outputs'\n",
    "DATASET = 'Benzene'\n",
    "\n",
    "# GNN\n",
    "MODEL = 'CMPNN' # Options:  ['MPNN', 'DMPNN', 'CMPNN', 'GIN', 'ECC', 'GAT', 'DGCNN', 'DiffPool', 'GraphSAGE', 'GraphNet']\n",
    "\n",
    "# explainer\n",
    "ATTRIBUTION = 'IG' # Options: IG CAM MCTS GradInput GradCAM RandomBaseline\n",
    "\n",
    "DATAPATH = '../Datasets/XAI/Benzene/benzene_smiles.csv'\n",
    "SMILESCOL = 'SMILES'\n",
    "TARGETCOL = 'label'\n",
    "\n",
    "ATTRIBUTIONPATH = '../Datasets/XAI/Benzene/attributions.npz'\n",
    "\n",
    "TASKTYPE = 'Classification' # Can be 'Multi-Classification', 'Classification', 'Regression'\n",
    "MULTICLASS_NUM_CLASSES = 2 # Can be 3\n",
    "TESTING = True\n",
    "SPLITTYPE = 'defined' # Can be 'random', 'scaffold', or other defined for dataset"
   ],
   "id": "97e7da87e9d3f7b7",
   "outputs": [],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T17:04:10.095466Z",
     "start_time": "2024-05-23T17:04:10.048593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import rdkit.Chem\n",
    "from MolRep.Utils.logger import Logger\n",
    "from MolRep.Explainer.explainerExperiments import ExplainerExperiments\n",
    "from MolRep.Explainer.explainerDataWrapper import ExplainerDatasetWrapper\n",
    "from MolRep.Utils.config_from_dict import Grid, Config, DatasetConfig\n",
    "from pathlib import Path\n",
    "import os\n",
    "from numba.cuda import args\n",
    "\n",
    "LOGGER_BASE = os.path.join(OUTPUT_DIR, \"Logger\", f\"{DATASET}_explainer\")\n",
    "logger = Logger(str(os.path.join(LOGGER_BASE, f\"{MODEL}_{DATASET}_explainer_by_{ATTRIBUTION}.log\")), mode='a')\n",
    "\n",
    "\n",
    "\n",
    "# output for vector groups\n",
    "data_dir = Path('../MolRep/Data')\n",
    "split_dir = Path('../MolRep/Splits')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "# moving down to have folders for different epoch numbers\n",
    "# svg_dir = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}\")\n",
    "# \n",
    "# # model output\n",
    "# output_dir = Path(OUTPUT_DIR)\n",
    "# MODELPATH = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", f\"{MODEL}.pt\")\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# os.makedirs(svg_dir, exist_ok=True)\n",
    "\n",
    "# torch.set_num_threads(1)\")\n",
    "data_stats = {\n",
    "            'name': DATASET,\n",
    "            'path': DATAPATH,\n",
    "            'smiles_column': SMILESCOL,\n",
    "            'target_columns': [TARGETCOL],\n",
    "            'attribution_path': ATTRIBUTIONPATH,\n",
    "            'task_type': TASKTYPE,\n",
    "            'multiclass_num_classes': MULTICLASS_NUM_CLASSES,\n",
    "            'metric_type': 'rmse' if TASKTYPE == 'Regression' else ['acc', 'auc', 'f1', 'precision', 'recall'],\n",
    "            'split_type': SPLITTYPE\n",
    "}\n",
    "\n",
    "if TESTING:\n",
    "    data_stats['additional_info'] = {\"splits\":'SPLIT'}"
   ],
   "id": "dfacd7f1cf8943f",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[177], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcuda\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m args\n\u001B[0;32m     10\u001B[0m LOGGER_BASE \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(OUTPUT_DIR, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLogger\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mDATASET\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_explainer\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 11\u001B[0m logger \u001B[38;5;241m=\u001B[39m Logger(\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mLOGGER_BASE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mMODEL\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mDATASET\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_explainer_by_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mATTRIBUTION\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.log\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# output for vector groups\u001B[39;00m\n\u001B[0;32m     16\u001B[0m data_dir \u001B[38;5;241m=\u001B[39m Path(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../MolRep/Data\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'list' object is not callable"
     ]
    }
   ],
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "id": "b8fbd60e86ed353b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T17:04:16.576836Z",
     "start_time": "2024-05-23T17:04:16.510945Z"
    }
   },
   "source": [
    "config_file = '../MolRep/Configs/config_{}.yml'.format(MODEL)\n",
    "model_configurations = Grid(config_file)\n",
    "model_configuration = Config(**model_configurations[0])\n",
    "dataset_configuration = DatasetConfig(DATASET, data_dict=data_stats)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMPNN\n",
      "{'GIN': <class 'MolRep.Models.graph_based.GIN.GIN'>, 'ECC': <class 'MolRep.Models.graph_based.ECC.ECC'>, 'DGCNN': <class 'MolRep.Models.graph_based.DGCNN.DGCNN'>, 'DiffPool': <class 'MolRep.Models.graph_based.DiffPool.DiffPool'>, 'GraphSAGE': <class 'MolRep.Models.graph_based.GraphSAGE.GraphSAGE'>, 'GAT': <class 'MolRep.Models.graph_based.GAT.GAT'>, 'GraphNet': <class 'MolRep.Models.graph_based.GraphNet.GraphNet'>, 'MPNN': <class 'MolRep.Models.graph_based.MPNN.MPNN'>, 'CMPNN': <class 'MolRep.Models.graph_based.CMPNN.CMPNN'>, 'DMPNN': <class 'MolRep.Models.graph_based.DMPNN.DMPNN'>, 'MAT': <class 'MolRep.Models.sequence_based.MAT.MAT'>, 'CoMPT': <class 'MolRep.Models.sequence_based.CoMPT.CoMPT'>, 'BiLSTM': <class 'MolRep.Models.sequence_based.BiLSTM.BiLSTM'>, 'SALSTM': <class 'MolRep.Models.sequence_based.SALSTM.SALSTM'>, 'Transformer': <class 'MolRep.Models.sequence_based.Transformer.Transformer'>, 'VAE': <class 'MolRep.Models.unsupervised_based.VAE.VAE'>, 'RandomForest': <class 'MolRep.Models.unsupervised_based.RandomForest.RandomForest'>, 'XGboost': <class 'MolRep.Models.unsupervised_based.XGboost.XGboost'>, 'PLNLP': <class 'MolRep.Interactions.link_models.PLNLP.PLNLP.PLNLP'>, 'CFLP': <class 'MolRep.Interactions.link_models.CFLP.CFLP.CFLP'>}\n"
     ]
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T17:04:18.870591Z",
     "start_time": "2024-05-23T17:04:18.859619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###### graphics go here\n",
    "svg_dir = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}_{model_configuration['num_epochs']}_epochs\")\n",
    "\n",
    "# model output\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "MODELPATH = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", f\"{MODEL}.pt\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(svg_dir, exist_ok=True)"
   ],
   "id": "b4e5f3f497340e9",
   "outputs": [],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T17:04:25.014678Z",
     "start_time": "2024-05-23T17:04:22.089489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exp_path = os.path.join(output_dir, f'{model_configuration.exp_name}_{dataset_configuration.exp_name}_explainer')\n",
    "\n",
    "dataset = ExplainerDatasetWrapper(dataset_config=dataset_configuration,\n",
    "                                  model_name=model_configuration.exp_name,\n",
    "                                  split_dir=split_dir, features_dir=data_dir)\n"
   ],
   "id": "6f5aafb16b07d4c3",
   "outputs": [],
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "id": "47bb5704c5de9081",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n",
    "explainer_experiment = ExplainerExperiments(model_configuration, dataset_configuration, exp_path)\n",
    "\n",
    "# validation\n",
    "explainer_experiment.run_valid(dataset, ATTRIBUTION, logger=logger, other={'model_path':MODELPATH})\n",
    "# if not os.path.exists(MODELPATH):\n",
    "#     explainer_experiment.run_valid(dataset, ATTRIBUTION, logger=logger, other={'model_path':MODELPATH})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f08bde043af69231",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "39cbd135f116d2a8",
   "metadata": {},
   "source": [
    "results, atom_importance, bond_importance = explainer_experiment.molecule_importance(dataset=dataset, attribution=ATTRIBUTION, logger=logger, other={'model_path':MODELPATH}, testing=TESTING)\n",
    "\n",
    "# model + dataset + explainer \\   = is smiles representations of the data? \n",
    "# .\\Outputs\\CMPNN_Liver_explainer\\CMPNN_explained_by_IG_oof.csv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7f8b2bc5b834b5f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2024-05-23T16:58:06.792832Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# logger.log('Test results: %s' % str(results))\n",
    "\n",
    "# print(attribution_results)\n",
    "\n",
    "if DATASET in ['hERG', 'CYP3A4']:\n",
    "    attribution_results, opt_threshold = explainer_experiment.evaluate_cliffs(dataset, atom_importance, bond_importance)\n",
    "else:\n",
    "    binary = True if ATTRIBUTION == 'MCTS' else False\n",
    "    #TODO not working, because ATTRIBUTIONPATH is not set and attributions are not saved\n",
    "    attribution_results, opt_threshold = explainer_experiment.evaluate_attributions(dataset, atom_importance, bond_importance, binary=binary)\n",
    "\n",
    "#TODO not working\n",
    "# logger.log('attribution_results:' + str(attribution_results))\n",
    "# logger.log('opt_threshold:' + str(opt_threshold))\n",
    "\n",
    "# create visualisations using  the dataset and learned atom and bond importances\n",
    "explainer_experiment.visualization(dataset, atom_importance, bond_importance, svg_dir=svg_dir, testing=TESTING)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'SMILES': dataset.get_smiles_list(), 'Atom_importance': atom_importance, 'Bond_importance':bond_importance}\n",
    ")\n",
    "df.to_csv(os.path.join(svg_dir, \"importances.csv\"), index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91954a28c3433d59",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T17:09:31.313198Z",
     "start_time": "2024-05-23T17:09:31.263363Z"
    }
   },
   "source": [
    "data = pd.read_csv(DATAPATH)[['SPLIT', 'label']]\n",
    "\n",
    "import pprint\n",
    "\n",
    "# print(\"Epochs: \", model_configuration['num_epochs'])\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "print(model_configuration['num_epochs'])\n",
    "print(results['acc'])\n",
    "print(results['auc'])\n",
    "print(results['f1'])\n",
    "print(results['precision'])\n",
    "print(results['recall'])\n",
    "print()\n",
    "print(attribution_results['Attribution AUROC'])\n",
    "print(attribution_results['Attribution F1'])\n",
    "print(attribution_results['Attribution ACC'])\n",
    "print(attribution_results['Attribution Precision'])\n",
    "print(attribution_results['Attribution AUROC Mean'])\n",
    "print(attribution_results['Attribution ACC Mean'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.7345833333333334\n",
      "0.8460620649374009\n",
      "0.7837011884550085\n",
      "0.6655132641291811\n",
      "0.9529314616019818\n",
      "\n",
      "0.9610136794981905\n",
      "0.0\n",
      "0.8153212876847543\n",
      "0.0\n",
      "0.9140292629203857\n",
      "0.8046728026701729\n"
     ]
    }
   ],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T17:56:47.054428Z",
     "start_time": "2024-05-23T17:56:47.037082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import rdkit\n",
    "import torch\n",
    "\n",
    "# MODEL = 'Outputs / 20240520_135930 / CMPNN_Benzene_explainer / CMPNN.pt'\n",
    "\n",
    "# smile, atom importances from df\n",
    "# use threshold to select atoms in the selection mask\n",
    "# use threshold to select atoms and bonds that need to be removed\n",
    "\n",
    "import copy\n",
    "\n",
    "# value of threshold is used in explainerExperiments.py in visualization\n",
    "def comp_and_suff(mol_idx, threshold=1e-4) :\n",
    "    smile = df.SMILES.iat[mol_idx]\n",
    "    importances = df.Atom_importance.iat[mol_idx]\n",
    "    \n",
    "    # convert importances from a string into array of floats\n",
    "    importances = [float(num) for num in importances.strip('[]').split()]\n",
    "    \n",
    "    original_mol = rdkit.Chem.RWMol(rdkit.Chem.MolFromSmiles(smile))\n",
    "     \n",
    "    non_explaining_atom_idx = []\n",
    "    explaining_atom_idx = []\n",
    "    for idx in range(len(original_mol.GetAtoms())):\n",
    "        # same threshold as one used for visualisation\n",
    "        if importances[idx] < threshold:\n",
    "            non_explaining_atom_idx.append(idx)\n",
    "        else:\n",
    "            explaining_atom_idx.append(idx)\n",
    "            \n",
    "    non_explaining_atom_idx.reverse()\n",
    "    explaining_atom_idx.reverse()\n",
    "    \n",
    "    # find (non)explaining bonds where at least one end is a non-explaining atom\n",
    "    non_explaining_bonds = []\n",
    "    explaining_bonds = []\n",
    "    \n",
    "    for bond in original_mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        \n",
    "        # if both end and start in explaining atoms, the edge is explaining \n",
    "        if (i and j) not in non_explaining_atom_idx :\n",
    "            explaining_bonds.append((i, j))\n",
    "            explaining_bonds.append((j, i))\n",
    "        else:\n",
    "            non_explaining_bonds.append((i, j))\n",
    "            non_explaining_bonds.append((j, i))\n",
    "    \n",
    "    # explaining molecule has non-explaining bonds and atoms removed \n",
    "    explaining_mol = copy.deepcopy(original_mol)\n",
    "    for (i, j) in non_explaining_bonds:\n",
    "        explaining_mol.RemoveBond(i, j)\n",
    "    \n",
    "    for idx in non_explaining_atom_idx:\n",
    "        explaining_mol.RemoveAtom(idx)\n",
    "    \n",
    "    explanation_smile = rdkit.Chem.MolToSmiles(explaining_mol)\n",
    "    \n",
    "    \n",
    "    # comprehensiveness uses non-explaining atoms and edges\n",
    "    non_explaining_mol = copy.deepcopy(original_mol)\n",
    "    \n",
    "    for (i, j) in explaining_bonds:\n",
    "        non_explaining_mol.RemoveBond(i, j)\n",
    "        \n",
    "    for i in explaining_atom_idx:\n",
    "        non_explaining_mol.RemoveAtom(i)\n",
    "    \n",
    "    non_explaining_smile = rdkit.Chem.MolToSmiles(non_explaining_mol)\n",
    "    \n",
    "    print(smile)\n",
    "    print(explanation_smile)\n",
    "    print(non_explaining_smile)\n",
    "    \n",
    "    ####\n",
    "    # TODO 2. priority separate fragments\n",
    "    # comprehensiveness leads to a degenerate smile when the explanation cuts the molecule in pieces, or when there are multiple substructures explaining\n",
    "    # if (non)explanation is in multiple fragments those could be evaluated separately\n",
    "    # ditto for sufficiency\n",
    "    # D/BFS\n",
    "    \n",
    "    \n",
    "    # TODO 1. priority prediction from smile\n",
    "    # torch.load(MODELPATH)\n",
    "    \n",
    "    # f = prediction with model \n",
    "    # comp = f(smile) - f(non_explaining_smile)\n",
    "    # suff = f (smile) - f(explaining_smile)\n",
    "    \n",
    "    comp = None\n",
    "    suff = None\n",
    "    return comp, suff\n"
   ],
   "id": "773ae384dee349e3",
   "outputs": [],
   "execution_count": 258
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:59:51.545623Z",
     "start_time": "2024-05-23T16:59:51.530661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import rdkit\n",
    "import torch\n",
    "# from MolRep.Models.metrics import fidelity\n",
    "from MolRep.Explainer.Metrics import attribution_metric\n",
    "\n",
    "model = model_configuration.models[MODEL]\n",
    "# \n",
    "# EXPLANATION_PATH = os.path.join(svg_dir, \"importances.csv\")\n",
    "# \n",
    "# df = pd.read_csv(EXPLANATION_PATH)\n",
    "# \n",
    "# smiles_importances = []\n",
    "# \n",
    "# for _, row in df.iterrows():\n",
    "#     smiles = row['SMILES']\n",
    "#     atom_importances = [float(num) for num in row['Atom_importance'].strip('[]').split()]\n",
    "#     smiles_importances.append({'smiles': smiles, 'atom_importances': atom_importance})\n",
    "# \n",
    "# print(smiles_importances[0])\n",
    "\n",
    "# df = pd.DataFrame(\n",
    "#     {'SMILES': dataset.get_smiles_list(), 'Atom_importance': atom_importance, 'Bond_importance':bond_importance}\n",
    "# )\n",
    "\n",
    "# -0.0018531113999999999\n",
    "# -0.00012721\n",
    "# explanation = None\n",
    "# test_dataset = dataset.get_smiles_list(testing = True)\n",
    "# \n",
    "# attribution_metric.suff_and_comp(0, model, explanation, test_dataset)"
   ],
   "id": "41ebcab894bb33a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-23T16:59:51.532657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def full_edge_matrix(dataset):\n",
    "    edges = []\n",
    "    for s in dataset.get_smiles_list():\n",
    "        m = rdkit.Chem.MolFromSmiles(s)\n",
    "        for e in m.GetBonds():\n",
    "            i = e.GetBeginAtomIdx()\n",
    "            j = e.GetBeginAtomIdx()\n",
    "            edges.append([i, j])\n",
    "            edges.append([j, i])\n",
    "    edges_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    return edges_index\n",
    "\n",
    "feature_matrix_atom = torch.tensor(atom_features(dataset), dtype=torch.float)\n",
    "edge_matrix = full_edge_matrix(dataset)\n",
    "\n",
    "# from torch_geometric.nn import GCNConv, MessagePassing\n",
    "\n",
    "node_mask = torch.ones((1, feature_matrix_atom.size(0)))\n",
    "node_mask[0] = 0\n",
    "\n",
    "# edge_index = set of all edges, but they also have features?\n",
    "# \n",
    "# model2 = model(dim_features=dataset.dim_features, dim_target=dataset.dim_target, model_configs=model_configuration, dataset_configs=dataset_configuration)\n",
    "# \n",
    "# fidelity(model2, 0, feature_matrix_atom, edge_matrix, node_mask)\n",
    "\n",
    "# from MolRep.Explainer.Metrics.attribution_metric import suff_and_comp\n",
    "# \n",
    "# suff, comp = suff_and_comp(model=model, idx=0, test_dataset=test_dataset, explanation=[-0.00012721,  0.00061489,  0.00043916,  0.0004554,  -0.00028018,  0.00096177,\n",
    "#   0.00123072,  0.00114732,  0.00098527,  0.00118253,  0.00141704,  0.00113096,\n",
    "#   0.00118042,  0.00109592,  0.00107567,  0.00034832,  0.00037524, 0.00040209])\n",
    "# \n",
    "# print(suff, comp)\n"
   ],
   "id": "a2a2374b4d1e49db",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
