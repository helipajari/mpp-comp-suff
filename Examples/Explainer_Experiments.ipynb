{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T09:54:02.424251Z",
     "start_time": "2024-05-28T09:54:02.407296Z"
    }
   },
   "source": [
    "# Converted by Tim Stols\n",
    "# python Explainer_Experiments.py --model_name CMPNN \\\n",
    "#                                                        --attribution_name GradInput \\\n",
    "#                                                        --data_path ../MolRep/Datasets/Metabolism/admet2.1_rlm_merge.csv \\\n",
    "#                                                        --dataset_name RLM \\\n",
    "#                                                        --smiles_col COMPOUND_SMILES \\\n",
    "#                                                        --target_col CLF_LABEL \\\n",
    "#                                                        --task_type Multi-Classification \\\n",
    "#                                                        --multiclass_num_classes 3 \\\n",
    "#                                                        --output_dir ../Outputs"
   ],
   "outputs": [],
   "execution_count": 349
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T09:54:02.472124Z",
     "start_time": "2024-05-28T09:54:02.454173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np"
   ],
   "id": "5d01e66301d55fb2",
   "outputs": [],
   "execution_count": 350
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T09:54:02.550913Z",
     "start_time": "2024-05-28T09:54:02.531964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# OUTPUT_DIR = f'../Outputs/{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "# # OUTPUT_DIR = '../Outputs'\n",
    "# DATASET = '3MR'\n",
    "# \n",
    "# # GNN\n",
    "# MODEL = 'GraphNet' # Options:  ['MPNN', 'DMPNN', 'CMPNN', 'GIN', 'ECC', 'GAT', 'DGCNN', 'DiffPool', 'GraphSAGE', 'GraphNet']\n",
    "# \n",
    "# # explainer\n",
    "# ATTRIBUTION = 'IG' # Options: IG CAM MCTS GradInput GradCAM RandomBaseline\n",
    "# \n",
    "# DATAPATH = '../DataSets/3MR/toy_label_mw350.csv'\n",
    "# SMILESCOL = 'SMILES'\n",
    "# TARGETCOL = 'label_full'\n",
    "# \n",
    "# ATTRIBUTIONPATH = '../DataSets/3MR/attributions.npz'\n",
    "# \n",
    "# TASKTYPE = 'Regression' # Can be 'Multi-Classification', 'Classification', 'Regression'\n",
    "# MULTICLASS_NUM_CLASSES = 2 # Can be 3\n",
    "# TESTING = True\n",
    "# SPLITTYPE = 'defined' # Can be 'random', 'scaffold', or other defined for dataset"
   ],
   "id": "21bea3823cc4b142",
   "outputs": [],
   "execution_count": 351
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T09:54:02.582832Z",
     "start_time": "2024-05-28T09:54:02.569862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# OUTPUT_DIR = f'../Outputs/{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "# # OUTPUT_DIR = '../Outputs'\n",
    "# DATASET = 'Liver'\n",
    "# \n",
    "# # GNN\n",
    "# MODEL = 'CMPNN' # Options:  ['MPNN', 'DMPNN', 'CMPNN', 'GIN', 'ECC', 'GAT', 'DGCNN', 'DiffPool', 'GraphSAGE', 'GraphNet']\n",
    "# \n",
    "# # explainer\n",
    "# ATTRIBUTION = 'IG' # Options: IG CAM MCTS GradInput GradCAM RandomBaseline\n",
    "# \n",
    "# DATAPATH = '../Datasets/XAI/Liver/liver.csv'\n",
    "# SMILESCOL = 'SMILES'\n",
    "# TARGETCOL = 'label'\n",
    "# \n",
    "# ATTRIBUTIONPATH = '../Datasets/XAI/Liver/attributions.npz'\n",
    "# \n",
    "# TASKTYPE = 'Classification' # Can be 'Multi-Classification', 'Classification', 'Regression'\n",
    "# MULTICLASS_NUM_CLASSES = 2 # Can be 3\n",
    "# TESTING = True\n",
    "# SPLITTYPE = 'defined' # Can be 'random', 'scaffold', or other defined for dataset"
   ],
   "id": "607c8ebd7f318ebd",
   "outputs": [],
   "execution_count": 352
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T09:54:02.613755Z",
     "start_time": "2024-05-28T09:54:02.603771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "OUTPUT_DIR = f'../Outputs/{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "# OUTPUT_DIR = '../Outputs'\n",
    "DATASET = 'Benzene'\n",
    "\n",
    "# GNN\n",
    "MODEL = 'CMPNN' # Options:  ['MPNN', 'DMPNN', 'CMPNN', 'GIN', 'ECC', 'GAT', 'DGCNN', 'DiffPool', 'GraphSAGE', 'GraphNet']\n",
    "\n",
    "# explainer\n",
    "ATTRIBUTION = 'IG' # Options: IG CAM MCTS GradInput GradCAM RandomBaseline\n",
    "\n",
    "DATAPATH = '../Datasets/XAI/Benzene/benzene_smiles.csv'\n",
    "# DATAPATH = '../Datasets/XAI/Benzene/benzene_smiles - with benzene.csv'\n",
    "SMILESCOL = 'SMILES'\n",
    "TARGETCOL = 'label'\n",
    "\n",
    "ATTRIBUTIONPATH = '../Datasets/XAI/Benzene/attributions.npz'\n",
    "\n",
    "TASKTYPE = 'Classification' # Can be 'Multi-Classification', 'Classification', 'Regression'\n",
    "MULTICLASS_NUM_CLASSES = 2 # Can be 3\n",
    "TESTING = True\n",
    "SPLITTYPE = 'defined' # Can be 'random', 'scaffold', or other defined for dataset"
   ],
   "id": "97e7da87e9d3f7b7",
   "outputs": [],
   "execution_count": 353
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T09:54:02.660618Z",
     "start_time": "2024-05-28T09:54:02.631697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import rdkit.Chem\n",
    "from MolRep.Utils.logger import Logger\n",
    "from MolRep.Explainer.explainerExperiments import ExplainerExperiments\n",
    "from MolRep.Explainer.explainerDataWrapper import ExplainerDatasetWrapper\n",
    "from MolRep.Utils.config_from_dict import Grid, Config, DatasetConfig\n",
    "from pathlib import Path\n",
    "import os\n",
    "from numba.cuda import args\n",
    "\n",
    "LOGGER_BASE = os.path.join(OUTPUT_DIR, \"Logger\", f\"{DATASET}_explainer\")\n",
    "logger = Logger(str(os.path.join(LOGGER_BASE, f\"{MODEL}_{DATASET}_explainer_by_{ATTRIBUTION}.log\")), mode='a')\n",
    "\n",
    "\n",
    "\n",
    "# output for vector groups\n",
    "data_dir = Path('../MolRep/Data')\n",
    "split_dir = Path('../MolRep/Splits')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "# moving down to have folders for different epoch numbers\n",
    "# svg_dir = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}\")\n",
    "# \n",
    "# # model output\n",
    "# output_dir = Path(OUTPUT_DIR)\n",
    "# MODELPATH = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", f\"{MODEL}.pt\")\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# os.makedirs(svg_dir, exist_ok=True)\n",
    "\n",
    "# torch.set_num_threads(1)\")\n",
    "data_stats = {\n",
    "            'name': DATASET,\n",
    "            'path': DATAPATH,\n",
    "            'smiles_column': SMILESCOL,\n",
    "            'target_columns': [TARGETCOL],\n",
    "            'attribution_path': ATTRIBUTIONPATH,\n",
    "            'task_type': TASKTYPE,\n",
    "            'multiclass_num_classes': MULTICLASS_NUM_CLASSES,\n",
    "            'metric_type': 'rmse' if TASKTYPE == 'Regression' else ['acc', 'auc', 'f1', 'precision', 'recall'],\n",
    "            'split_type': SPLITTYPE\n",
    "}\n",
    "\n",
    "if TESTING:\n",
    "    data_stats['additional_info'] = {\"splits\":'SPLIT'}"
   ],
   "id": "dfacd7f1cf8943f",
   "outputs": [],
   "execution_count": 354
  },
  {
   "cell_type": "code",
   "id": "b8fbd60e86ed353b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-28T09:54:02.754368Z",
     "start_time": "2024-05-28T09:54:02.670592Z"
    }
   },
   "source": [
    "config_file = '../MolRep/Configs/config_{}.yml'.format(MODEL)\n",
    "model_configurations = Grid(config_file)\n",
    "model_configuration = Config(**model_configurations[0])\n",
    "dataset_configuration = DatasetConfig(DATASET, data_dict=data_stats)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMPNN\n",
      "{'GIN': <class 'MolRep.Models.graph_based.GIN.GIN'>, 'ECC': <class 'MolRep.Models.graph_based.ECC.ECC'>, 'DGCNN': <class 'MolRep.Models.graph_based.DGCNN.DGCNN'>, 'DiffPool': <class 'MolRep.Models.graph_based.DiffPool.DiffPool'>, 'GraphSAGE': <class 'MolRep.Models.graph_based.GraphSAGE.GraphSAGE'>, 'GAT': <class 'MolRep.Models.graph_based.GAT.GAT'>, 'GraphNet': <class 'MolRep.Models.graph_based.GraphNet.GraphNet'>, 'MPNN': <class 'MolRep.Models.graph_based.MPNN.MPNN'>, 'CMPNN': <class 'MolRep.Models.graph_based.CMPNN.CMPNN'>, 'DMPNN': <class 'MolRep.Models.graph_based.DMPNN.DMPNN'>, 'MAT': <class 'MolRep.Models.sequence_based.MAT.MAT'>, 'CoMPT': <class 'MolRep.Models.sequence_based.CoMPT.CoMPT'>, 'BiLSTM': <class 'MolRep.Models.sequence_based.BiLSTM.BiLSTM'>, 'SALSTM': <class 'MolRep.Models.sequence_based.SALSTM.SALSTM'>, 'Transformer': <class 'MolRep.Models.sequence_based.Transformer.Transformer'>, 'VAE': <class 'MolRep.Models.unsupervised_based.VAE.VAE'>, 'RandomForest': <class 'MolRep.Models.unsupervised_based.RandomForest.RandomForest'>, 'XGboost': <class 'MolRep.Models.unsupervised_based.XGboost.XGboost'>, 'PLNLP': <class 'MolRep.Interactions.link_models.PLNLP.PLNLP.PLNLP'>, 'CFLP': <class 'MolRep.Interactions.link_models.CFLP.CFLP.CFLP'>}\n"
     ]
    }
   ],
   "execution_count": 355
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T09:54:02.769333Z",
     "start_time": "2024-05-28T09:54:02.757361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###### graphics go here\n",
    "svg_dir = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", \"SVG\", f\"{ATTRIBUTION}_{model_configuration['num_epochs']}_epochs\")\n",
    "\n",
    "# model output\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "MODELPATH = os.path.join(OUTPUT_DIR, f\"{MODEL}_{DATASET}_explainer\", f\"{MODEL}.pt\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(svg_dir, exist_ok=True)"
   ],
   "id": "b4e5f3f497340e9",
   "outputs": [],
   "execution_count": 356
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T09:54:06.957162Z",
     "start_time": "2024-05-28T09:54:02.773318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exp_path = os.path.join(output_dir, f'{model_configuration.exp_name}_{dataset_configuration.exp_name}_explainer')\n",
    "\n",
    "dataset = ExplainerDatasetWrapper(dataset_config=dataset_configuration,\n",
    "                                  model_name=model_configuration.exp_name,\n",
    "                                  split_dir=split_dir, features_dir=data_dir)\n"
   ],
   "id": "6f5aafb16b07d4c3",
   "outputs": [],
   "execution_count": 357
  },
  {
   "cell_type": "code",
   "id": "47bb5704c5de9081",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-28T09:54:07.083859Z",
     "start_time": "2024-05-28T09:54:06.961151Z"
    }
   },
   "source": [
    "\n",
    "explainer_experiment = ExplainerExperiments(model_configuration, dataset_configuration, exp_path)\n",
    "\n",
    "\n",
    "# test_smiles = dataset.get_smiles_list(testing=True)\n",
    "# print(\"test\")\n",
    "# print(test_smiles[0:3])\n",
    "# \n",
    "# train_smiles = dataset.get_smiles_list(testing=False)\n",
    "# print(\"train\")\n",
    "# # benzene added to train set despite assignment to testing?\n",
    "# print(train_smiles[0:3])\n",
    "# \n",
    "\n",
    "# validation, with new data breaks\n",
    "explainer_experiment.run_valid(dataset, ATTRIBUTION, logger=logger, other={'model_path':MODELPATH})\n",
    "# if not os.path.exists(MODELPATH):\n",
    "#     explainer_experiment.run_valid(dataset, ATTRIBUTION, logger=logger, other={'model_path':MODELPATH})"
   ],
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 12000 is out of bounds for axis 0 with size 12000",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[358], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m explainer_experiment \u001B[38;5;241m=\u001B[39m ExplainerExperiments(model_configuration, dataset_configuration, exp_path)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# validation\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[43mexplainer_experiment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_valid\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mATTRIBUTION\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel_path\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mMODELPATH\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# if not os.path.exists(MODELPATH):\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#     explainer_experiment.run_valid(dataset, ATTRIBUTION, logger=logger, other={'model_path':MODELPATH})\u001B[39;00m\n",
      "File \u001B[1;32mC:\\git\\rp-repo\\hpajari-Explainable-graph-models-for-biological-and-chemi\\MolRep\\Explainer\\explainerExperiments.py:106\u001B[0m, in \u001B[0;36mExplainerExperiments.run_valid\u001B[1;34m(self, dataset, attribution, logger, other)\u001B[0m\n\u001B[0;32m    103\u001B[0m loss_fn \u001B[38;5;241m=\u001B[39m get_loss_func(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask_type\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_config\u001B[38;5;241m.\u001B[39mexp_name)\n\u001B[0;32m    104\u001B[0m shuffle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mshuffle\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mshuffle\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_config \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 106\u001B[0m train_loader, valid_loader, features_scaler, scaler \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_train_loader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbatch_size\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m                                                \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    109\u001B[0m model \u001B[38;5;241m=\u001B[39m model_class(dim_features\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mdim_features, dim_target\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mdim_target, model_configs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_config, dataset_configs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_config)\n\u001B[0;32m    110\u001B[0m net \u001B[38;5;241m=\u001B[39m ExplainerNetWrapper(model, attribution, dataset_configs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_config, model_config\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_config,\n\u001B[0;32m    111\u001B[0m                           loss_function\u001B[38;5;241m=\u001B[39mloss_fn)\n",
      "File \u001B[1;32mC:\\git\\rp-repo\\hpajari-Explainable-graph-models-for-biological-and-chemi\\MolRep\\Explainer\\explainerDataWrapper.py:247\u001B[0m, in \u001B[0;36mExplainerDatasetWrapper.get_train_loader\u001B[1;34m(self, batch_size, shuffle, features_scaling)\u001B[0m\n\u001B[0;32m    243\u001B[0m     train_loader, valid_loader, _, features_scaler, scaler \u001B[38;5;241m=\u001B[39m Graph_data\u001B[38;5;241m.\u001B[39mGraph_construct_dataloader(\n\u001B[0;32m    244\u001B[0m         trainset\u001B[38;5;241m=\u001B[39mtrain_dataset, validset\u001B[38;5;241m=\u001B[39mvalid_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39mshuffle, task_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_type, features_scaling\u001B[38;5;241m=\u001B[39mfeatures_scaling)\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_name \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMPNN\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDMPNN\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCMPNN\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m--> 247\u001B[0m     train_dataset, valid_dataset, _ \u001B[38;5;241m=\u001B[39m \u001B[43mMPNN_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMPNN_construct_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    248\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_idxs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrainset_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_idxs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidset_indices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    250\u001B[0m     train_loader, valid_loader, _, features_scaler, scaler \u001B[38;5;241m=\u001B[39m MPNN_data\u001B[38;5;241m.\u001B[39mMPNN_construct_dataloader(\n\u001B[0;32m    251\u001B[0m         trainset\u001B[38;5;241m=\u001B[39mtrain_dataset, validset\u001B[38;5;241m=\u001B[39mvalid_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39mshuffle, task_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_type, features_scaling\u001B[38;5;241m=\u001B[39mfeatures_scaling)\n\u001B[0;32m    253\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m: \n",
      "File \u001B[1;32mC:\\git\\rp-repo\\hpajari-Explainable-graph-models-for-biological-and-chemi\\MolRep\\Experiments\\Graph_Data\\MPNN_data.py:532\u001B[0m, in \u001B[0;36mMPNN_construct_dataset\u001B[1;34m(features_path, train_idxs, valid_idxs, test_idxs)\u001B[0m\n\u001B[0;32m    529\u001B[0m dataset \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(features_path)\n\u001B[0;32m    530\u001B[0m smiles_all, x_all, y_all \u001B[38;5;241m=\u001B[39m dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msmiles_all\u001B[39m\u001B[38;5;124m\"\u001B[39m], dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_all\u001B[39m\u001B[38;5;124m\"\u001B[39m], dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_all\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m--> 532\u001B[0m trainset \u001B[38;5;241m=\u001B[39m _construct_dataset(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43msmiles_all\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain_idxs\u001B[49m\u001B[43m]\u001B[49m, np\u001B[38;5;241m.\u001B[39marray(x_all)[train_idxs], np\u001B[38;5;241m.\u001B[39marray(y_all)[train_idxs]) \u001B[38;5;28;01mif\u001B[39;00m train_idxs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    533\u001B[0m validset \u001B[38;5;241m=\u001B[39m _construct_dataset(np\u001B[38;5;241m.\u001B[39marray(smiles_all)[valid_idxs], np\u001B[38;5;241m.\u001B[39marray(x_all)[valid_idxs], np\u001B[38;5;241m.\u001B[39marray(y_all)[valid_idxs]) \u001B[38;5;28;01mif\u001B[39;00m valid_idxs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    534\u001B[0m testset \u001B[38;5;241m=\u001B[39m _construct_dataset(np\u001B[38;5;241m.\u001B[39marray(smiles_all)[test_idxs], np\u001B[38;5;241m.\u001B[39marray(x_all)[test_idxs], np\u001B[38;5;241m.\u001B[39marray(y_all)[test_idxs]) \u001B[38;5;28;01mif\u001B[39;00m test_idxs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mIndexError\u001B[0m: index 12000 is out of bounds for axis 0 with size 12000"
     ]
    }
   ],
   "execution_count": 358
  },
  {
   "cell_type": "code",
   "id": "f08bde043af69231",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "39cbd135f116d2a8",
   "metadata": {},
   "source": [
    "results, atom_importance, bond_importance = explainer_experiment.molecule_importance(dataset=dataset, attribution=ATTRIBUTION, logger=logger, other={'model_path':MODELPATH}, testing=TESTING)\n",
    "\n",
    "# model + dataset + explainer \\   = is smiles representations of the data? \n",
    "# .\\Outputs\\CMPNN_Liver_explainer\\CMPNN_explained_by_IG_oof.csv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7b0a945551da7bbc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "import rdkit.Chem as chem\n",
    "\n",
    "id = chem.MolFromSmiles(\"c1ccccc1\")\n",
    "id2 = chem.MolFromSmiles(\"C1CCCCC1\")\n",
    "\n",
    "print(id, id2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# logger.log('Test results: %s' % str(results))\n",
    "\n",
    "# print(attribution_results)\n",
    "\n",
    "if DATASET in ['hERG', 'CYP3A4']:\n",
    "    attribution_results, opt_threshold = explainer_experiment.evaluate_cliffs(dataset, atom_importance, bond_importance)\n",
    "else:\n",
    "    binary = True if ATTRIBUTION == 'MCTS' else False\n",
    "    #TODO not working, because ATTRIBUTIONPATH is not set and attributions are not saved\n",
    "    attribution_results, opt_threshold = explainer_experiment.evaluate_attributions(dataset, atom_importance, bond_importance, binary=binary)"
   ],
   "id": "9a27b08b200a9c17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#TODO not working\n",
    "# logger.log('attribution_results:' + str(attribution_results))\n",
    "# logger.log('opt_threshold:' + str(opt_threshold))\n",
    "\n",
    "# create visualisations using  the dataset and learned atom and bond importances\n",
    "\n",
    " \n",
    "# c1cc(ncc1NC(=O)C1CCCCC1)n1cc(cn1)S(=O)(=O)N \n",
    "\n",
    "# def get_smiles_list(self, testing=True, training=False):\n",
    "#     whole_smiles = self.whole_data_df.loc[:,self.smiles_col].values\n",
    "#     if testing:\n",
    "#         testset_indices = self.splits[0][\"test\"]\n",
    "#     elif training:\n",
    "#         testset_indices = self.splits[0][\"model_selection\"][0][\"train\"]\n",
    "#     else:\n",
    "#         testset_indices = np.arange(len(whole_smiles))\n",
    "#     return whole_smiles[testset_indices]\n",
    "\n",
    "\n",
    "# testing = True returns both benzene and the carbon hex ring, b = 1 test, c6 = 0 train, 3rd = 0 train\n",
    "\n",
    "# test_smiles = dataset.get_smiles_list(testing=True)\n",
    "# print(\"test\")\n",
    "# print(test_smiles[0:3])\n",
    "# \n",
    "# train_smiles = dataset.get_smiles_list(testing=False)\n",
    "# print(\"train\")\n",
    "# # benzene added to train set despite assignment to testing?\n",
    "# print(train_smiles[0:3])"
   ],
   "id": "395bfa5898070076",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "explainer_experiment.visualization(dataset, atom_importance, bond_importance, svg_dir=svg_dir, testing=TESTING)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'SMILES': dataset.get_smiles_list(), 'Atom_importance': atom_importance, 'Bond_importance':bond_importance}\n",
    ")\n",
    "df.to_csv(os.path.join(svg_dir, \"importances.csv\"), index=False)"
   ],
   "id": "b7f8b2bc5b834b5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91954a28c3433d59",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "data = pd.read_csv(DATAPATH)[['SPLIT', 'label']]\n",
    "\n",
    "import pprint\n",
    "\n",
    "# print(\"Epochs: \", model_configuration['num_epochs'])\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "print(model_configuration['num_epochs'])\n",
    "print(results['acc'])\n",
    "print(results['auc'])\n",
    "print(results['f1'])\n",
    "print(results['precision'])\n",
    "print(results['recall'])\n",
    "print()\n",
    "print(attribution_results['Attribution AUROC'])\n",
    "print(attribution_results['Attribution F1'])\n",
    "print(attribution_results['Attribution ACC'])\n",
    "print(attribution_results['Attribution Precision'])\n",
    "print(attribution_results['Attribution AUROC Mean'])\n",
    "print(attribution_results['Attribution ACC Mean'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T11:36:57.003926Z",
     "start_time": "2024-05-28T11:36:56.986004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "\n",
    "def split_molecule(mol_idx:int, threshold=1e-4):\n",
    "    \"\"\"Splits the given molecule into explaining and non-explaining SMILES, returns those and the SMILES of the molecule. Threshold value is the same as in explainerExperiments.py visualization()\"\"\"\n",
    "    smile = df.SMILES.iat[mol_idx]\n",
    "\n",
    "    # TODO get test indices, index by the index in the test set\n",
    "    importances = df.Atom_importance.iat[mol_idx]\n",
    "\n",
    "    # atom importance with big set\n",
    "    \n",
    "    original_mol = rdkit.Chem.RWMol(rdkit.Chem.MolFromSmiles(smile))\n",
    "     \n",
    "    non_explaining_atom_idx = []\n",
    "    explaining_atom_idx = []\n",
    "    for idx in range(len(original_mol.GetAtoms())):\n",
    "        if importances[idx] < threshold:\n",
    "            non_explaining_atom_idx.append(idx)\n",
    "        else:\n",
    "            explaining_atom_idx.append(idx)\n",
    "            \n",
    "    # reverse because removing atoms causes indices of others to shift\n",
    "    non_explaining_atom_idx.reverse()\n",
    "    explaining_atom_idx.reverse()\n",
    "    \n",
    "    # find (non)explaining bonds where at least one end is a non-explaining atom\n",
    "    non_explaining_bonds = []\n",
    "    explaining_bonds = []\n",
    "    \n",
    "    for bond in original_mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        \n",
    "        # if both end and start in explaining atoms, the edge is explaining \n",
    "        if (i and j) not in non_explaining_atom_idx :\n",
    "            explaining_bonds.append((i, j))\n",
    "            explaining_bonds.append((j, i))\n",
    "        else:\n",
    "            non_explaining_bonds.append((i, j))\n",
    "            non_explaining_bonds.append((j, i))\n",
    "            \n",
    "            # remove i or j from explaining atoms to keep the bond in non-explaining molecules\n",
    "            if i in explaining_atom_idx: explaining_atom_idx.remove(i)\n",
    "            if j in explaining_atom_idx: explaining_atom_idx.remove(j)\n",
    "    \n",
    "    # explaining molecule has non-explaining bonds and atoms removed\n",
    "    explaining_mol = copy.deepcopy(original_mol)\n",
    "    for (i, j) in non_explaining_bonds:\n",
    "        explaining_mol.RemoveBond(i, j)\n",
    "    \n",
    "    for idx in non_explaining_atom_idx:\n",
    "        explaining_mol.RemoveAtom(idx)\n",
    "\n",
    "    explaining_smile = \"\"\n",
    "    if len(explaining_mol.GetAtoms() > 0):\n",
    "        explaining_smile = rdkit.Chem.MolToSmiles(explaining_mol)\n",
    "    \n",
    "    # comprehensiveness uses non-explaining atoms and edges\n",
    "    non_explaining_mol = copy.deepcopy(original_mol)\n",
    "    \n",
    "    for (i, j) in explaining_bonds:\n",
    "        non_explaining_mol.RemoveBond(i, j)\n",
    "    \n",
    "    # remove explaining atoms unless it has a bond to a non-explaining atom    \n",
    "    for i in explaining_atom_idx:\n",
    "        non_explaining_mol.RemoveAtom(i)\n",
    "    \n",
    "    non_explaining_smile = \"\"\n",
    "    # edge case: there are no non-explaining edges\n",
    "    if len(non_explaining_mol.GetAtoms()) > 0:\n",
    "        non_explaining_smile = rdkit.Chem.MolToSmiles(non_explaining_mol)\n",
    "    \n",
    "    # if (mol_idx == 3):\n",
    "    #     print(\"hiii\")\n",
    "    #     print(smile)\n",
    "    #     print(explaining_smile)\n",
    "    #     print(non_explaining_smile)\n",
    "    #     # print(importances)\n",
    "    # print(smile)\n",
    "    \n",
    "    return smile, explaining_smile, non_explaining_smile"
   ],
   "id": "da3b8f1ab4ebbc4",
   "outputs": [],
   "execution_count": 395
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from MolRep.Featurization.MPNN_embeddings import MolGraph, BatchMolGraph\n",
    "from rdkit.Chem import MolFromSmiles, rdmolops\n",
    "\n",
    "def tensors_to_device(smile, batch):\n",
    "    \"\"\"Sets nodes, edges, a2b, b2a and adjacency matrix tensors of a molecule to the device\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    adj = rdmolops.GetAdjacencyMatrix(MolFromSmiles(smile))\n",
    "    \n",
    "    list = {\n",
    "        'nodes' : batch.f_atoms, \n",
    "        'edges' : batch.f_bonds,\n",
    "        'a2b' : batch.a2b,\n",
    "        'b2a' : batch.b2a,\n",
    "        'adjacency' : torch.FloatTensor(adj) \n",
    "    }\n",
    "    \n",
    "    for i in list:\n",
    "        list[i].to(device)\n",
    "        \n",
    "    return list['nodes'], list['edges'], list['a2b'], list['b2a'], list['adjacency']"
   ],
   "id": "ebf3d2ee8dfcd116",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T12:23:37.410679Z",
     "start_time": "2024-05-28T12:23:37.226174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def clean_smiles(s:str) -> str:\n",
    "    \"\"\"Takes a (fragmented) SMILES as input and returns valid fragments of it as a new SMILES. Does nothing if input is already valid.\n",
    "    e.g: C.CC.F.O.n.n -> C.CC.F.O\n",
    "    \"\"\"\n",
    "    cs = \"\"\n",
    "    # 1. split string\n",
    "    subm = s.split('.')\n",
    "\n",
    "    # 2. if piece converts to a molgraph, append to cs\n",
    "    for (i, sm) in enumerate(subm):\n",
    "        try:\n",
    "            MolGraph(sm)\n",
    "            cs += sm\n",
    "            if i < len(subm) - 1:\n",
    "                cs += '.'\n",
    "        except:\n",
    "            if i < len(subm) - 1:\n",
    "                cs += '.'\n",
    "            continue\n",
    "\n",
    "    # 3. remove repeating . and the last . from the string\n",
    "    cs = re.sub(\"\\.+\", \".\", cs)\n",
    "    # ReGeX from https://stackoverflow.com/a/3331982\n",
    "    cs = re.sub(\"\\.([^.]*)$\", \"\", cs)\n",
    "    return cs"
   ],
   "id": "1d4cc16ded7064dd",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Outputs/20240528_115402\\\\CMPNN_Benzene_explainer\\\\CMPNN.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[424], line 112\u001B[0m\n\u001B[0;32m    109\u001B[0m         c_and_s\u001B[38;5;241m.\u001B[39mappend(vals)\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m c_and_s\n\u001B[1;32m--> 112\u001B[0m g_pred, comp, suff \u001B[38;5;241m=\u001B[39m \u001B[43mcomp_and_suff\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;66;03m# print('comp:', comp)\u001B[39;00m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;66;03m# print('suff:', suff)\u001B[39;00m\n\u001B[0;32m    116\u001B[0m c \u001B[38;5;241m=\u001B[39m comp_and_suff_data(df)\n",
      "Cell \u001B[1;32mIn[424], line 15\u001B[0m, in \u001B[0;36mcomp_and_suff\u001B[1;34m(i)\u001B[0m\n\u001B[0;32m     11\u001B[0m smile, explaining_smile, non_explaining_smile \u001B[38;5;241m=\u001B[39m split_molecule(i)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# smile, explaining_smile, non_explaining_smile = \"c1ccccc1\", \"c1ccccc1\", \"\"\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mexplainer_experiment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel_path\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mMODELPATH\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     19\u001B[0m preds \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32mC:\\git\\rp-repo\\hpajari-Explainable-graph-models-for-biological-and-chemi\\MolRep\\Explainer\\explainerExperiments.py:133\u001B[0m, in \u001B[0;36mExplainerExperiments.get_model\u001B[1;34m(self, dataset, other)\u001B[0m\n\u001B[0;32m    129\u001B[0m model \u001B[38;5;241m=\u001B[39m model_class(dim_features\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mdim_features, dim_target\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mdim_target,\n\u001B[0;32m    130\u001B[0m                     model_configs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_config, dataset_configs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_config)\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_path\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m other\u001B[38;5;241m.\u001B[39mkeys()\n\u001B[1;32m--> 133\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mother\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel_path\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32mC:\\git\\rp-repo\\hpajari-Explainable-graph-models-for-biological-and-chemi\\MolRep\\Utils\\utils.py:184\u001B[0m, in \u001B[0;36mload_checkpoint\u001B[1;34m(path, model, current_args, cuda, logger)\u001B[0m\n\u001B[0;32m    181\u001B[0m debug \u001B[38;5;241m=\u001B[39m logger\u001B[38;5;241m.\u001B[39minfo \u001B[38;5;28;01mif\u001B[39;00m logger \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mprint\u001B[39m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;66;03m# Load model and args\u001B[39;00m\n\u001B[1;32m--> 184\u001B[0m state \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloc\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    185\u001B[0m args, loaded_state_dict \u001B[38;5;241m=\u001B[39m state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m'\u001B[39m], state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate_dict\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m current_args \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mc:\\git\\rp\\explainable-graph-models-for-biological-and-chemi-main\\venv\\lib\\site-packages\\torch\\serialization.py:997\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m    994\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    995\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 997\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m    998\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m    999\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1000\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1001\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1002\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32mc:\\git\\rp\\explainable-graph-models-for-biological-and-chemi-main\\venv\\lib\\site-packages\\torch\\serialization.py:444\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    442\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    443\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 444\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    446\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32mc:\\git\\rp\\explainable-graph-models-for-biological-and-chemi-main\\venv\\lib\\site-packages\\torch\\serialization.py:425\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    424\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 425\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../Outputs/20240528_115402\\\\CMPNN_Benzene_explainer\\\\CMPNN.pt'"
     ]
    }
   ],
   "execution_count": 424
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def comp_and_suff(i) :\n",
    "    \"\"\"Calculate comprehensiveness and sufficiency for a molecule with index i.\"\"\"\n",
    "    model = explainer_experiment.get_model(dataset, other={'model_path':MODELPATH})\n",
    "    model.eval() # set model to evaluation mode\n",
    "\n",
    "    smile, explaining_smile, non_explaining_smile = split_molecule(i)\n",
    "\n",
    "    preds = []\n",
    "    for s in [smile, explaining_smile, non_explaining_smile] :\n",
    "        # split may have resulted in invalid smiles\n",
    "        cs = clean_smiles(s)\n",
    "\n",
    "        print(\"s\", s)\n",
    "        print(\"cs\", cs)\n",
    "\n",
    "        # 3. try to convert to molgraph\n",
    "        # TODO if iterating explaining smile -> do each fragment separately\n",
    "        try:\n",
    "            mol = MolGraph(cs)\n",
    "            g_input = BatchMolGraph( [mol])\n",
    "            atoms, bonds, a2b, b2a, adjacency = tensors_to_device(cs, g_input)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # TODO investigate None params\n",
    "                #   Args for mol2graph:\n",
    "                # - mols: A list of SMILES or a list of RDKit molecules.\n",
    "                # - atom_descriptors_batch: A list of 2D numpy array containing additional atom descriptors to featurize the molecule\n",
    "                pred = model([[cs], None, None]).item()\n",
    "                # print(pred)\n",
    "\n",
    "            print(i, ' pred for ', cs, ': ', pred)\n",
    "            preds.append(pred)\n",
    "        except:\n",
    "            # in case smile is an empty string, append None to indicate comp or suff can't be calculated\n",
    "            preds.append(None)\n",
    "            continue\n",
    "\n",
    "    g_pred = preds[0] # prediction of original molecule\n",
    "    e_pred = preds[1] # prediction of explaining molecule\n",
    "    n_pred = preds[2] # prediction of non-explaining molecule\n",
    "\n",
    "    # f = model prediction\n",
    "    # comp = f(smile) - f(non_explaining_smile)\n",
    "    # suff = f (smile) - f(explaining_smile)\n",
    "\n",
    "    comp = None\n",
    "    suff = None\n",
    "\n",
    "    if n_pred is not None:\n",
    "        comp = g_pred - n_pred\n",
    "    if e_pred is not None:\n",
    "        suff = g_pred - e_pred\n",
    "\n",
    "    return [g_pred, comp, suff]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def comp_and_suff_data(df):\n",
    "    c_and_s = []\n",
    "    # TODO 1 breaks at idx 3\n",
    "    # test or train indices\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        # only calculate comp and suff for molecules in the test set i.e. which have explanations\n",
    "        if i in dataset.get_smiles_idxs(testing=True):\n",
    "            vals = comp_and_suff(i)\n",
    "            print(i, vals)\n",
    "            c_and_s.append(vals)\n",
    "    return c_and_s\n",
    "\n",
    "g_pred, comp, suff = comp_and_suff(3)\n",
    "# print('comp:', comp)\n",
    "# print('suff:', suff)\n",
    "\n",
    "c = comp_and_suff_data(df)\n",
    "print(type(c))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T11:51:29.411274Z",
     "start_time": "2024-05-28T11:51:29.398309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO 2 further work\n",
    "# save results of comp-suff for transparency\n",
    "# use a different explainer on the model\n",
    "# save those results"
   ],
   "id": "773ae384dee349e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs C.CC.F.O..\n",
      "cs C.CC.F.O\n"
     ]
    }
   ],
   "execution_count": 422
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}